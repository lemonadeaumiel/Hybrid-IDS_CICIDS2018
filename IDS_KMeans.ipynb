{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e12e5d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc6a21a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc498500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49db2488",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e860448",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./CICIDS_2018/IDS.csv',index_col=[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdbd8391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>TotLen Fwd Pkts</th>\n",
       "      <th>TotLen Bwd Pkts</th>\n",
       "      <th>Fwd Pkt Len Max</th>\n",
       "      <th>Fwd Pkt Len Min</th>\n",
       "      <th>Fwd Pkt Len Mean</th>\n",
       "      <th>Fwd Pkt Len Std</th>\n",
       "      <th>Bwd Pkt Len Max</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5631664</th>\n",
       "      <td>2116.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3099750</th>\n",
       "      <td>1057.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825967</th>\n",
       "      <td>66555644.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>3886.0</td>\n",
       "      <td>5154.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111.028571</td>\n",
       "      <td>174.330735</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8191292.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8191292.0</td>\n",
       "      <td>8191292.0</td>\n",
       "      <td>58302685.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58302685.0</td>\n",
       "      <td>58302685.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7113878</th>\n",
       "      <td>2462909.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>1466.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>190.919579</td>\n",
       "      <td>1149.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566689</th>\n",
       "      <td>322.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420640</th>\n",
       "      <td>18184</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>87</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Infilteration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490836</th>\n",
       "      <td>14208808</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>674</td>\n",
       "      <td>5918</td>\n",
       "      <td>517</td>\n",
       "      <td>0</td>\n",
       "      <td>61.27272727</td>\n",
       "      <td>155.8294522</td>\n",
       "      <td>1460</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>3051885</td>\n",
       "      <td>0</td>\n",
       "      <td>3051885</td>\n",
       "      <td>3051885</td>\n",
       "      <td>6014723</td>\n",
       "      <td>0</td>\n",
       "      <td>6014723</td>\n",
       "      <td>6014723</td>\n",
       "      <td>Infilteration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537625</th>\n",
       "      <td>5124568</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Infilteration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21838</th>\n",
       "      <td>Flow Duration</td>\n",
       "      <td>Tot Fwd Pkts</td>\n",
       "      <td>Tot Bwd Pkts</td>\n",
       "      <td>TotLen Fwd Pkts</td>\n",
       "      <td>TotLen Bwd Pkts</td>\n",
       "      <td>Fwd Pkt Len Max</td>\n",
       "      <td>Fwd Pkt Len Min</td>\n",
       "      <td>Fwd Pkt Len Mean</td>\n",
       "      <td>Fwd Pkt Len Std</td>\n",
       "      <td>Bwd Pkt Len Max</td>\n",
       "      <td>...</td>\n",
       "      <td>Fwd Seg Size Min</td>\n",
       "      <td>Active Mean</td>\n",
       "      <td>Active Std</td>\n",
       "      <td>Active Max</td>\n",
       "      <td>Active Min</td>\n",
       "      <td>Idle Mean</td>\n",
       "      <td>Idle Std</td>\n",
       "      <td>Idle Max</td>\n",
       "      <td>Idle Min</td>\n",
       "      <td>Label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510114</th>\n",
       "      <td>Flow Duration</td>\n",
       "      <td>Tot Fwd Pkts</td>\n",
       "      <td>Tot Bwd Pkts</td>\n",
       "      <td>TotLen Fwd Pkts</td>\n",
       "      <td>TotLen Bwd Pkts</td>\n",
       "      <td>Fwd Pkt Len Max</td>\n",
       "      <td>Fwd Pkt Len Min</td>\n",
       "      <td>Fwd Pkt Len Mean</td>\n",
       "      <td>Fwd Pkt Len Std</td>\n",
       "      <td>Bwd Pkt Len Max</td>\n",
       "      <td>...</td>\n",
       "      <td>Fwd Seg Size Min</td>\n",
       "      <td>Active Mean</td>\n",
       "      <td>Active Std</td>\n",
       "      <td>Active Max</td>\n",
       "      <td>Active Min</td>\n",
       "      <td>Idle Mean</td>\n",
       "      <td>Idle Std</td>\n",
       "      <td>Idle Max</td>\n",
       "      <td>Idle Min</td>\n",
       "      <td>Label</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>811375 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Flow Duration  Tot Fwd Pkts  Tot Bwd Pkts  TotLen Fwd Pkts  \\\n",
       "5631664         2116.0           1.0           1.0             44.0   \n",
       "3099750         1057.0           1.0           1.0             41.0   \n",
       "1825967     66555644.0          35.0          46.0           3886.0   \n",
       "7113878      2462909.0           8.0           8.0           1032.0   \n",
       "1566689          322.0           1.0           1.0             47.0   \n",
       "...                ...           ...           ...              ...   \n",
       "420640           18184             1             1               31   \n",
       "490836        14208808            11             8              674   \n",
       "537625         5124568             3             1                0   \n",
       "21838    Flow Duration  Tot Fwd Pkts  Tot Bwd Pkts  TotLen Fwd Pkts   \n",
       "510114   Flow Duration  Tot Fwd Pkts  Tot Bwd Pkts  TotLen Fwd Pkts   \n",
       "\n",
       "         TotLen Bwd Pkts  Fwd Pkt Len Max  Fwd Pkt Len Min  Fwd Pkt Len Mean  \\\n",
       "5631664             82.0             44.0             44.0              44.0   \n",
       "3099750            103.0             41.0             41.0              41.0   \n",
       "1825967           5154.0            583.0              0.0        111.028571   \n",
       "7113878           1466.0            565.0              0.0             129.0   \n",
       "1566689             63.0             47.0             47.0              47.0   \n",
       "...                  ...              ...              ...               ...   \n",
       "420640                87               31               31                31   \n",
       "490836              5918              517                0       61.27272727   \n",
       "537625                 0                0                0                 0   \n",
       "21838    TotLen Bwd Pkts  Fwd Pkt Len Max  Fwd Pkt Len Min  Fwd Pkt Len Mean   \n",
       "510114   TotLen Bwd Pkts  Fwd Pkt Len Max  Fwd Pkt Len Min  Fwd Pkt Len Mean   \n",
       "\n",
       "         Fwd Pkt Len Std  Bwd Pkt Len Max  ...  Fwd Seg Size Min  Active Mean  \\\n",
       "5631664              0.0             82.0  ...               8.0          0.0   \n",
       "3099750              0.0            103.0  ...               8.0          0.0   \n",
       "1825967       174.330735           1430.0  ...              20.0    8191292.0   \n",
       "7113878       190.919579           1149.0  ...              20.0          0.0   \n",
       "1566689              0.0             63.0  ...               8.0          0.0   \n",
       "...                  ...              ...  ...               ...          ...   \n",
       "420640                 0               87  ...                 8            0   \n",
       "490836       155.8294522             1460  ...                20      3051885   \n",
       "537625                 0                0  ...                20            0   \n",
       "21838    Fwd Pkt Len Std  Bwd Pkt Len Max  ...  Fwd Seg Size Min  Active Mean   \n",
       "510114   Fwd Pkt Len Std  Bwd Pkt Len Max  ...  Fwd Seg Size Min  Active Mean   \n",
       "\n",
       "         Active Std  Active Max  Active Min   Idle Mean  Idle Std    Idle Max  \\\n",
       "5631664         0.0         0.0         0.0         0.0       0.0         0.0   \n",
       "3099750         0.0         0.0         0.0         0.0       0.0         0.0   \n",
       "1825967         0.0   8191292.0   8191292.0  58302685.0       0.0  58302685.0   \n",
       "7113878         0.0         0.0         0.0         0.0       0.0         0.0   \n",
       "1566689         0.0         0.0         0.0         0.0       0.0         0.0   \n",
       "...             ...         ...         ...         ...       ...         ...   \n",
       "420640            0           0           0           0         0           0   \n",
       "490836            0     3051885     3051885     6014723         0     6014723   \n",
       "537625            0           0           0           0         0           0   \n",
       "21838    Active Std  Active Max  Active Min   Idle Mean  Idle Std    Idle Max   \n",
       "510114   Active Std  Active Max  Active Min   Idle Mean  Idle Std    Idle Max   \n",
       "\n",
       "           Idle Min          Label  \n",
       "5631664         0.0         Benign  \n",
       "3099750         0.0         Benign  \n",
       "1825967  58302685.0         Benign  \n",
       "7113878         0.0         Benign  \n",
       "1566689         0.0         Benign  \n",
       "...             ...            ...  \n",
       "420640            0  Infilteration  \n",
       "490836      6014723  Infilteration  \n",
       "537625            0  Infilteration  \n",
       "21838      Idle Min          Label  \n",
       "510114     Idle Min          Label  \n",
       "\n",
       "[811375 rows x 77 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3353388f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.loc[df['Label'] == 'Label'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf0b0d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benign                      674154\n",
       "DDOS attack-HOIC             34301\n",
       "DDoS attacks-LOIC-HTTP       28810\n",
       "DoS attacks-Hulk             23096\n",
       "Bot                          14116\n",
       "FTP-BruteForce                9668\n",
       "SSH-Bruteforce                9379\n",
       "Infilteration                 8096\n",
       "DoS attacks-SlowHTTPTest      6994\n",
       "DoS attacks-GoldenEye         2075\n",
       "DoS attacks-Slowloris          550\n",
       "DDOS attack-LOIC-UDP            86\n",
       "Brute Force -Web                30\n",
       "Brute Force -XSS                12\n",
       "SQL Injection                    5\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdfa9032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts',\n",
       "       'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min',\n",
       "       'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Bwd Pkt Len Max',\n",
       "       'Bwd Pkt Len Min', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Flow Byts/s',\n",
       "       'Flow Pkts/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max',\n",
       "       'Flow IAT Min', 'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Std',\n",
       "       'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Tot', 'Bwd IAT Mean',\n",
       "       'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags',\n",
       "       'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Len',\n",
       "       'Bwd Header Len', 'Fwd Pkts/s', 'Bwd Pkts/s', 'Pkt Len Min',\n",
       "       'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Std', 'Pkt Len Var',\n",
       "       'FIN Flag Cnt', 'SYN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt',\n",
       "       'ACK Flag Cnt', 'URG Flag Cnt', 'CWE Flag Count', 'ECE Flag Cnt',\n",
       "       'Down/Up Ratio', 'Pkt Size Avg', 'Fwd Seg Size Avg', 'Bwd Seg Size Avg',\n",
       "       'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg',\n",
       "       'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg',\n",
       "       'Subflow Fwd Pkts', 'Subflow Fwd Byts', 'Subflow Bwd Pkts',\n",
       "       'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts',\n",
       "       'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std',\n",
       "       'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max',\n",
       "       'Idle Min', 'Label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba6c0243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c9151a",
   "metadata": {},
   "source": [
    "### Preprocessing (normalization and padding values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "738993d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "df.iloc[:, -1] = labelencoder.fit_transform(df.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c154116",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb055b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Flow Duration  Tot Fwd Pkts  Tot Bwd Pkts  TotLen Fwd Pkts  \\\n",
      "5631664      -0.394745     -0.015187     -0.035153        -0.018825   \n",
      "3099750      -0.394780     -0.015187     -0.035153        -0.018885   \n",
      "1825967       1.759464      0.006932      0.269120         0.057650   \n",
      "7113878      -0.315094     -0.010633      0.012178         0.000841   \n",
      "1566689      -0.394803     -0.015187     -0.035153        -0.018765   \n",
      "...                ...           ...           ...              ...   \n",
      "469282       -0.394794     -0.015187     -0.035153        -0.019064   \n",
      "504000       -0.349719     -0.010633      0.005416         0.003150   \n",
      "420640       -0.394225     -0.015187     -0.035153        -0.019084   \n",
      "490836        0.065098     -0.008681      0.012178        -0.006285   \n",
      "537625       -0.228941     -0.013886     -0.035153        -0.019701   \n",
      "\n",
      "         TotLen Bwd Pkts  Fwd Pkt Len Max  Fwd Pkt Len Min  Fwd Pkt Len Mean  \\\n",
      "5631664        -0.021068        -0.508047         1.367593         -0.101207   \n",
      "3099750        -0.020970        -0.517767         1.243022         -0.149330   \n",
      "1825967         0.002650         1.238257        -0.459452          0.973996   \n",
      "7113878        -0.014596         1.179938        -0.459452          1.262275   \n",
      "1566689        -0.021157        -0.498327         1.492164         -0.053084   \n",
      "...                  ...              ...              ...               ...   \n",
      "469282         -0.021227        -0.546926         0.869308         -0.293698   \n",
      "504000         -0.014058         1.542807        -0.459452          1.494869   \n",
      "420640         -0.021045        -0.550165         0.827784         -0.309739   \n",
      "490836          0.006223         1.024423        -0.459452          0.175864   \n",
      "537625         -0.021452        -0.650602        -0.459452         -0.807009   \n",
      "\n",
      "         Fwd Pkt Len Std  Bwd Pkt Len Max  ...  Fwd Seg Size Min  Active Mean  \\\n",
      "5631664        -0.601549        -0.539825  ...         -1.297894    -0.069433   \n",
      "3099750        -0.601549        -0.497557  ...         -1.297894    -0.069433   \n",
      "1825967         0.878416         2.173370  ...          0.261140     3.143011   \n",
      "7113878         1.019245         1.607786  ...          0.261140    -0.069433   \n",
      "1566689        -0.601549        -0.578067  ...         -1.297894    -0.069433   \n",
      "...                  ...              ...  ...               ...          ...   \n",
      "469282         -0.601549        -0.608258  ...         -1.297894    -0.069433   \n",
      "504000          1.335137         1.656092  ...          0.261140    -0.069433   \n",
      "420640         -0.601549        -0.529761  ...         -1.297894    -0.069433   \n",
      "490836          0.721351         2.233753  ...          0.261140     1.127449   \n",
      "537625         -0.601549        -0.704871  ...          0.261140    -0.069433   \n",
      "\n",
      "         Active Std  Active Max  Active Min  Idle Mean  Idle Std  Idle Max  \\\n",
      "5631664   -0.057395   -0.079483   -0.054963  -0.302176 -0.090334 -0.305447   \n",
      "3099750   -0.057395   -0.079483   -0.054963  -0.302176 -0.090334 -0.305447   \n",
      "1825967   -0.057395    2.355413    3.742835   3.368978 -0.090334  3.309281   \n",
      "7113878   -0.057395   -0.079483   -0.054963  -0.302176 -0.090334 -0.305447   \n",
      "1566689   -0.057395   -0.079483   -0.054963  -0.302176 -0.090334 -0.305447   \n",
      "...             ...         ...         ...        ...       ...       ...   \n",
      "469282    -0.057395   -0.079483   -0.054963  -0.302176 -0.090334 -0.305447   \n",
      "504000    -0.057395   -0.079483   -0.054963  -0.302176 -0.090334 -0.305447   \n",
      "420640    -0.057395   -0.079483   -0.054963  -0.302176 -0.090334 -0.305447   \n",
      "490836    -0.057395    0.827703    1.360008   0.076554 -0.090334  0.067462   \n",
      "537625    -0.057395   -0.079483   -0.054963  -0.302176 -0.090334 -0.305447   \n",
      "\n",
      "         Idle Min     Label  \n",
      "5631664 -0.295557 -0.391384  \n",
      "3099750 -0.295557 -0.391384  \n",
      "1825967  3.403867 -0.391384  \n",
      "7113878 -0.295557 -0.391384  \n",
      "1566689 -0.295557 -0.391384  \n",
      "...           ...       ...  \n",
      "469282  -0.295557  3.718002  \n",
      "504000  -0.295557  3.718002  \n",
      "420640  -0.295557  3.718002  \n",
      "490836   0.086090  3.718002  \n",
      "537625  -0.295557  3.718002  \n",
      "\n",
      "[811372 rows x 77 columns]\n"
     ]
    }
   ],
   "source": [
    "# Z-score normalization\n",
    "features = df.dtypes.index\n",
    "df[features] = df[features].apply(\n",
    "    lambda x: (x - x.mean()) / (x.std()))\n",
    "print(df[features])\n",
    "# Fill empty values by 0\n",
    "df = df.fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeebee76",
   "metadata": {},
   "source": [
    "### Data sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "043e5d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "df.iloc[:, -1] = labelencoder.fit_transform(df.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09383b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     674154\n",
       "4      34301\n",
       "6      28810\n",
       "8      23096\n",
       "1      14116\n",
       "11      9668\n",
       "14      9379\n",
       "12      8096\n",
       "9       6994\n",
       "7       2075\n",
       "10       550\n",
       "5         86\n",
       "2         30\n",
       "3         12\n",
       "13         5\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df.isin([np.inf, -np.inf]).any(axis=1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c8404aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retain the minority class instances\n",
    "df_minor = df[(df['Label'] == 0) | (df['Label'] == 4) | (df['Label'] == 6) | (df['Label'] == 8) | (\n",
    "    df['Label'] == 1) | (df['Label'] == 11) | (df['Label'] == 14) | (df['Label'] == 12) | (df['Label'] == 9) | (df['Label'] == 7) ]\n",
    "df_major = df.drop(df_minor.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc6eb6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_major.drop(['Label'],axis=1)\n",
    "X = X[X.replace([np.inf, -np.inf], np.nan).notnull().all(axis=1)]\n",
    "X = X.astype(np.float64, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc72e425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  2  2  2  2  2  2  2  2  2  2  3  3  3  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  3  3  3 13]\n"
     ]
    }
   ],
   "source": [
    "y = df_major.iloc[:, -1].values.reshape(-1, 1)\n",
    "y = np.ravel(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49e2d899",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[X > 1e308] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7266c7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.any(np.isinf(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3852571a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for n_clusters :  4 , the average silhouette_score is : 0.7857904174523094\n",
      "for n_clusters :  5 , the average silhouette_score is : 0.7566007580793052\n",
      "for n_clusters :  6 , the average silhouette_score is : 0.7581060920365768\n",
      "for n_clusters :  7 , the average silhouette_score is : 0.7828588390658231\n",
      "for n_clusters :  8 , the average silhouette_score is : 0.7811733583293067\n",
      "for n_clusters :  9 , the average silhouette_score is : 0.7341825501731775\n"
     ]
    }
   ],
   "source": [
    "# use k-means to cluster the data samples and select a proportion of data from each cluster\n",
    "from sklearn.cluster import KMeans\n",
    "# from default to the number of labels\n",
    "range_n_clusters = [4,5,6,7,8,9]\n",
    "silhouette_avg = []\n",
    "for num_clusters in range_n_clusters:\n",
    "    # initialise kmeans \n",
    "    kmeans = KMeans(init='k-means++', n_clusters=num_clusters)\n",
    "    kmeans.fit(X)\n",
    "    cluster_labels = kmeans.labels_\n",
    "    # Compute the silhouette scores for each sample\n",
    "    silhouette_avg.append(silhouette_score(X, cluster_labels))\n",
    "    \n",
    "for i in range(len(silhouette_avg)):\n",
    "    print(\n",
    "        \"for n_clusters : \",\n",
    "        range_n_clusters[i],\n",
    "        \", the average silhouette_score is :\",\n",
    "        silhouette_avg[i]\n",
    "    )\n",
    "#best score is while n_clusters=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39c061b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 3, 2, 2, 0, 2, 0, 2, 2, 0, 2, 3, 2, 0, 2, 0, 3, 0, 2,\n",
       "       2, 2, 2, 3, 0, 0, 3, 3, 3, 3, 2, 0, 0, 3, 0, 2, 2, 3, 2, 2, 3, 3,\n",
       "       2, 2, 0, 0, 2, 0, 0, 0, 3, 0, 2, 0, 0, 3, 3, 0, 2, 0, 2, 0, 0, 0,\n",
       "       3, 3, 3, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 0, 2, 2, 0, 3, 2, 2, 2,\n",
       "       3, 2, 3, 0, 0, 2, 2, 0, 2, 2, 0, 2, 0, 3, 2, 2, 2, 2, 3, 0, 2, 3,\n",
       "       0, 2, 2, 3, 0, 0, 2, 0, 0, 0, 2, 2, 3, 3, 2, 0, 2, 3, 0, 0, 3, 2,\n",
       "       0, 2, 2, 2, 0, 0, 0, 2, 3, 2, 2, 0, 2, 3, 3, 2, 0, 3, 2, 0, 0, 0,\n",
       "       2, 0, 2, 2, 2, 0, 2, 2, 0, 2, 0, 3, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0,\n",
       "       2, 0, 2, 2, 2, 3, 0, 0, 0, 0, 0, 0, 0, 3, 2, 3, 0, 2, 0, 2, 2, 3,\n",
       "       2, 0, 3, 3, 0, 3, 3, 0, 3, 3, 0, 0, 3, 0, 0, 2, 2, 2, 2, 3, 2, 2,\n",
       "       3, 0, 0, 3, 0, 0, 0, 2, 0, 2, 0, 3, 3, 2, 2, 0, 2, 2, 0, 0, 0, 3,\n",
       "       0, 3, 3, 3, 2, 3, 0, 2, 0, 3, 2, 0, 2, 2, 2, 2, 0, 2, 3, 0, 0, 2,\n",
       "       2, 2, 3, 0, 2, 2, 2, 0, 2, 3, 2, 3, 3, 3, 2, 2, 0, 0, 0, 2, 3, 2,\n",
       "       2, 2, 2, 3, 2, 2, 2, 2, 3, 3, 0, 2, 0, 2, 2, 2, 2, 2, 2, 0, 3, 3,\n",
       "       2, 2, 0, 3, 0, 2, 2, 0, 0, 0, 2, 3, 2, 2, 0, 0, 2, 2, 2, 3, 2, 0,\n",
       "       0, 3, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 2, 0, 3, 2, 2, 3, 2, 3, 2,\n",
       "       2, 2, 0, 3, 2, 0, 0, 2, 2, 2, 0, 3, 0, 2, 0, 2, 0, 2, 0, 2, 0, 3,\n",
       "       3, 0, 0, 2, 1, 4, 1, 4, 1, 5, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 5, 4,\n",
       "       4, 1, 1, 4, 5, 4, 1, 1, 1, 1, 7, 1, 1, 7, 1, 1, 4, 1, 4, 1, 1, 5,\n",
       "       1, 1, 1, 5, 1, 4, 1, 1, 1, 1, 1, 7, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 6, 0, 6, 0, 6, 6, 6, 0, 0, 0, 0,\n",
       "       0, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(init='k-means++', n_clusters=8)\n",
    "kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ce17dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "klabel = kmeans.labels_\n",
    "df_major['klabel'] = klabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55e89cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    169\n",
       "2    156\n",
       "3     79\n",
       "1     37\n",
       "4      9\n",
       "5      6\n",
       "6      6\n",
       "7      3\n",
       "Name: klabel, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_major['klabel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a02f3b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(df_major)\n",
    "cols.insert(78, cols.pop(cols.index('Label')))\n",
    "df_major = df_major.loc[:, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba557f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>TotLen Fwd Pkts</th>\n",
       "      <th>TotLen Bwd Pkts</th>\n",
       "      <th>Fwd Pkt Len Max</th>\n",
       "      <th>Fwd Pkt Len Min</th>\n",
       "      <th>Fwd Pkt Len Mean</th>\n",
       "      <th>Fwd Pkt Len Std</th>\n",
       "      <th>Bwd Pkt Len Max</th>\n",
       "      <th>...</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>klabel</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45582</th>\n",
       "      <td>-0.297083</td>\n",
       "      <td>-0.013886</td>\n",
       "      <td>-0.041915</td>\n",
       "      <td>-0.019701</td>\n",
       "      <td>-0.021452</td>\n",
       "      <td>-0.650602</td>\n",
       "      <td>-0.459452</td>\n",
       "      <td>-0.807009</td>\n",
       "      <td>-0.601549</td>\n",
       "      <td>-0.704871</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069433</td>\n",
       "      <td>-0.057395</td>\n",
       "      <td>-0.079483</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.302176</td>\n",
       "      <td>-0.090334</td>\n",
       "      <td>-0.305447</td>\n",
       "      <td>-0.295557</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45980</th>\n",
       "      <td>-0.296937</td>\n",
       "      <td>-0.013886</td>\n",
       "      <td>-0.041915</td>\n",
       "      <td>-0.019701</td>\n",
       "      <td>-0.021452</td>\n",
       "      <td>-0.650602</td>\n",
       "      <td>-0.459452</td>\n",
       "      <td>-0.807009</td>\n",
       "      <td>-0.601549</td>\n",
       "      <td>-0.704871</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069433</td>\n",
       "      <td>-0.057395</td>\n",
       "      <td>-0.079483</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.302176</td>\n",
       "      <td>-0.090334</td>\n",
       "      <td>-0.305447</td>\n",
       "      <td>-0.295557</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43613</th>\n",
       "      <td>-0.296816</td>\n",
       "      <td>-0.013886</td>\n",
       "      <td>-0.041915</td>\n",
       "      <td>-0.019701</td>\n",
       "      <td>-0.021452</td>\n",
       "      <td>-0.650602</td>\n",
       "      <td>-0.459452</td>\n",
       "      <td>-0.807009</td>\n",
       "      <td>-0.601549</td>\n",
       "      <td>-0.704871</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069433</td>\n",
       "      <td>-0.057395</td>\n",
       "      <td>-0.079483</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.302176</td>\n",
       "      <td>-0.090334</td>\n",
       "      <td>-0.305447</td>\n",
       "      <td>-0.295557</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35702</th>\n",
       "      <td>-0.296300</td>\n",
       "      <td>-0.013886</td>\n",
       "      <td>-0.041915</td>\n",
       "      <td>-0.019701</td>\n",
       "      <td>-0.021452</td>\n",
       "      <td>-0.650602</td>\n",
       "      <td>-0.459452</td>\n",
       "      <td>-0.807009</td>\n",
       "      <td>-0.601549</td>\n",
       "      <td>-0.704871</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069433</td>\n",
       "      <td>-0.057395</td>\n",
       "      <td>-0.079483</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.302176</td>\n",
       "      <td>-0.090334</td>\n",
       "      <td>-0.305447</td>\n",
       "      <td>-0.295557</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30816</th>\n",
       "      <td>2.841982</td>\n",
       "      <td>-0.014536</td>\n",
       "      <td>-0.028392</td>\n",
       "      <td>-0.019382</td>\n",
       "      <td>-0.021452</td>\n",
       "      <td>-0.624683</td>\n",
       "      <td>-0.127262</td>\n",
       "      <td>-0.678681</td>\n",
       "      <td>-0.601549</td>\n",
       "      <td>-0.704871</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069432</td>\n",
       "      <td>-0.057395</td>\n",
       "      <td>-0.079482</td>\n",
       "      <td>-0.054961</td>\n",
       "      <td>5.994517</td>\n",
       "      <td>-0.090334</td>\n",
       "      <td>5.894466</td>\n",
       "      <td>6.049624</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>-0.232787</td>\n",
       "      <td>-0.012585</td>\n",
       "      <td>-0.021630</td>\n",
       "      <td>-0.006842</td>\n",
       "      <td>-0.019750</td>\n",
       "      <td>1.442370</td>\n",
       "      <td>-0.459452</td>\n",
       "      <td>1.265483</td>\n",
       "      <td>1.851041</td>\n",
       "      <td>0.027772</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069433</td>\n",
       "      <td>-0.057395</td>\n",
       "      <td>-0.079483</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.302176</td>\n",
       "      <td>-0.090334</td>\n",
       "      <td>-0.305447</td>\n",
       "      <td>-0.295557</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>-0.394795</td>\n",
       "      <td>-0.014536</td>\n",
       "      <td>-0.041915</td>\n",
       "      <td>-0.019701</td>\n",
       "      <td>-0.021452</td>\n",
       "      <td>-0.650602</td>\n",
       "      <td>-0.459452</td>\n",
       "      <td>-0.807009</td>\n",
       "      <td>-0.601549</td>\n",
       "      <td>-0.704871</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069433</td>\n",
       "      <td>-0.057395</td>\n",
       "      <td>-0.079483</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.302176</td>\n",
       "      <td>-0.090334</td>\n",
       "      <td>-0.305447</td>\n",
       "      <td>-0.295557</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>-0.394809</td>\n",
       "      <td>-0.014536</td>\n",
       "      <td>-0.041915</td>\n",
       "      <td>-0.019701</td>\n",
       "      <td>-0.021452</td>\n",
       "      <td>-0.650602</td>\n",
       "      <td>-0.459452</td>\n",
       "      <td>-0.807009</td>\n",
       "      <td>-0.601549</td>\n",
       "      <td>-0.704871</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069433</td>\n",
       "      <td>-0.057395</td>\n",
       "      <td>-0.079483</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.302176</td>\n",
       "      <td>-0.090334</td>\n",
       "      <td>-0.305447</td>\n",
       "      <td>-0.295557</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>-0.394810</td>\n",
       "      <td>-0.014536</td>\n",
       "      <td>-0.041915</td>\n",
       "      <td>-0.019701</td>\n",
       "      <td>-0.021452</td>\n",
       "      <td>-0.650602</td>\n",
       "      <td>-0.459452</td>\n",
       "      <td>-0.807009</td>\n",
       "      <td>-0.601549</td>\n",
       "      <td>-0.704871</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069433</td>\n",
       "      <td>-0.057395</td>\n",
       "      <td>-0.079483</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.302176</td>\n",
       "      <td>-0.090334</td>\n",
       "      <td>-0.305447</td>\n",
       "      <td>-0.295557</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>-0.232369</td>\n",
       "      <td>-0.012585</td>\n",
       "      <td>-0.008107</td>\n",
       "      <td>-0.010843</td>\n",
       "      <td>-0.007025</td>\n",
       "      <td>0.791151</td>\n",
       "      <td>-0.459452</td>\n",
       "      <td>0.620637</td>\n",
       "      <td>1.087929</td>\n",
       "      <td>5.172376</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069433</td>\n",
       "      <td>-0.057395</td>\n",
       "      <td>-0.079483</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.302176</td>\n",
       "      <td>-0.090334</td>\n",
       "      <td>-0.305447</td>\n",
       "      <td>-0.295557</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>465 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Flow Duration  Tot Fwd Pkts  Tot Bwd Pkts  TotLen Fwd Pkts  \\\n",
       "45582      -0.297083     -0.013886     -0.041915        -0.019701   \n",
       "45980      -0.296937     -0.013886     -0.041915        -0.019701   \n",
       "43613      -0.296816     -0.013886     -0.041915        -0.019701   \n",
       "35702      -0.296300     -0.013886     -0.041915        -0.019701   \n",
       "30816       2.841982     -0.014536     -0.028392        -0.019382   \n",
       "...              ...           ...           ...              ...   \n",
       "379        -0.232787     -0.012585     -0.021630        -0.006842   \n",
       "1229       -0.394795     -0.014536     -0.041915        -0.019701   \n",
       "1075       -0.394809     -0.014536     -0.041915        -0.019701   \n",
       "1189       -0.394810     -0.014536     -0.041915        -0.019701   \n",
       "1508       -0.232369     -0.012585     -0.008107        -0.010843   \n",
       "\n",
       "       TotLen Bwd Pkts  Fwd Pkt Len Max  Fwd Pkt Len Min  Fwd Pkt Len Mean  \\\n",
       "45582        -0.021452        -0.650602        -0.459452         -0.807009   \n",
       "45980        -0.021452        -0.650602        -0.459452         -0.807009   \n",
       "43613        -0.021452        -0.650602        -0.459452         -0.807009   \n",
       "35702        -0.021452        -0.650602        -0.459452         -0.807009   \n",
       "30816        -0.021452        -0.624683        -0.127262         -0.678681   \n",
       "...                ...              ...              ...               ...   \n",
       "379          -0.019750         1.442370        -0.459452          1.265483   \n",
       "1229         -0.021452        -0.650602        -0.459452         -0.807009   \n",
       "1075         -0.021452        -0.650602        -0.459452         -0.807009   \n",
       "1189         -0.021452        -0.650602        -0.459452         -0.807009   \n",
       "1508         -0.007025         0.791151        -0.459452          0.620637   \n",
       "\n",
       "       Fwd Pkt Len Std  Bwd Pkt Len Max  ...  Active Mean  Active Std  \\\n",
       "45582        -0.601549        -0.704871  ...    -0.069433   -0.057395   \n",
       "45980        -0.601549        -0.704871  ...    -0.069433   -0.057395   \n",
       "43613        -0.601549        -0.704871  ...    -0.069433   -0.057395   \n",
       "35702        -0.601549        -0.704871  ...    -0.069433   -0.057395   \n",
       "30816        -0.601549        -0.704871  ...    -0.069432   -0.057395   \n",
       "...                ...              ...  ...          ...         ...   \n",
       "379           1.851041         0.027772  ...    -0.069433   -0.057395   \n",
       "1229         -0.601549        -0.704871  ...    -0.069433   -0.057395   \n",
       "1075         -0.601549        -0.704871  ...    -0.069433   -0.057395   \n",
       "1189         -0.601549        -0.704871  ...    -0.069433   -0.057395   \n",
       "1508          1.087929         5.172376  ...    -0.069433   -0.057395   \n",
       "\n",
       "       Active Max  Active Min  Idle Mean  Idle Std  Idle Max  Idle Min  \\\n",
       "45582   -0.079483   -0.054963  -0.302176 -0.090334 -0.305447 -0.295557   \n",
       "45980   -0.079483   -0.054963  -0.302176 -0.090334 -0.305447 -0.295557   \n",
       "43613   -0.079483   -0.054963  -0.302176 -0.090334 -0.305447 -0.295557   \n",
       "35702   -0.079483   -0.054963  -0.302176 -0.090334 -0.305447 -0.295557   \n",
       "30816   -0.079482   -0.054961   5.994517 -0.090334  5.894466  6.049624   \n",
       "...           ...         ...        ...       ...       ...       ...   \n",
       "379     -0.079483   -0.054963  -0.302176 -0.090334 -0.305447 -0.295557   \n",
       "1229    -0.079483   -0.054963  -0.302176 -0.090334 -0.305447 -0.295557   \n",
       "1075    -0.079483   -0.054963  -0.302176 -0.090334 -0.305447 -0.295557   \n",
       "1189    -0.079483   -0.054963  -0.302176 -0.090334 -0.305447 -0.295557   \n",
       "1508    -0.079483   -0.054963  -0.302176 -0.090334 -0.305447 -0.295557   \n",
       "\n",
       "       klabel  Label  \n",
       "45582       0     10  \n",
       "45980       0     10  \n",
       "43613       0     10  \n",
       "35702       0     10  \n",
       "30816       3     10  \n",
       "...       ...    ...  \n",
       "379         0      2  \n",
       "1229        0      3  \n",
       "1075        0      3  \n",
       "1189        0      3  \n",
       "1508        0     13  \n",
       "\n",
       "[465 rows x 78 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0c74583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def typicalSampling(group):\n",
    "    name = group.name\n",
    "    frac = 100\n",
    "    return group.sample(frac=frac, replace= True)\n",
    "\n",
    "result = df_major.groupby('klabel', group_keys=False\n",
    ").apply(typicalSampling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4baca9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    37672\n",
       "5      5500\n",
       "2      2598\n",
       "3       618\n",
       "13      112\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a192c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.drop(['klabel'], axis=1)\n",
    "result = result.append(df_minor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ce44591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>TotLen Fwd Pkts</th>\n",
       "      <th>TotLen Bwd Pkts</th>\n",
       "      <th>Fwd Pkt Len Max</th>\n",
       "      <th>Fwd Pkt Len Min</th>\n",
       "      <th>Fwd Pkt Len Mean</th>\n",
       "      <th>Fwd Pkt Len Std</th>\n",
       "      <th>Bwd Pkt Len Max</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50387</th>\n",
       "      <td>-0.296443</td>\n",
       "      <td>-0.013886</td>\n",
       "      <td>-0.041915</td>\n",
       "      <td>-0.019701</td>\n",
       "      <td>-0.021452</td>\n",
       "      <td>-0.650602</td>\n",
       "      <td>-0.459452</td>\n",
       "      <td>-0.807009</td>\n",
       "      <td>-0.601549</td>\n",
       "      <td>-0.704871</td>\n",
       "      <td>...</td>\n",
       "      <td>2.859529</td>\n",
       "      <td>-0.069433</td>\n",
       "      <td>-0.057395</td>\n",
       "      <td>-0.079483</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.302176</td>\n",
       "      <td>-0.090334</td>\n",
       "      <td>-0.305447</td>\n",
       "      <td>-0.295557</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39981</th>\n",
       "      <td>-0.296171</td>\n",
       "      <td>-0.013886</td>\n",
       "      <td>-0.041915</td>\n",
       "      <td>-0.019701</td>\n",
       "      <td>-0.021452</td>\n",
       "      <td>-0.650602</td>\n",
       "      <td>-0.459452</td>\n",
       "      <td>-0.807009</td>\n",
       "      <td>-0.601549</td>\n",
       "      <td>-0.704871</td>\n",
       "      <td>...</td>\n",
       "      <td>2.859529</td>\n",
       "      <td>-0.069433</td>\n",
       "      <td>-0.057395</td>\n",
       "      <td>-0.079483</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.302176</td>\n",
       "      <td>-0.090334</td>\n",
       "      <td>-0.305447</td>\n",
       "      <td>-0.295557</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32972</th>\n",
       "      <td>-0.394804</td>\n",
       "      <td>-0.015187</td>\n",
       "      <td>-0.028392</td>\n",
       "      <td>-0.014963</td>\n",
       "      <td>-0.019039</td>\n",
       "      <td>0.120493</td>\n",
       "      <td>9.423202</td>\n",
       "      <td>3.010740</td>\n",
       "      <td>-0.601549</td>\n",
       "      <td>0.333711</td>\n",
       "      <td>...</td>\n",
       "      <td>1.820173</td>\n",
       "      <td>-0.069433</td>\n",
       "      <td>-0.057395</td>\n",
       "      <td>-0.079483</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.302176</td>\n",
       "      <td>-0.090334</td>\n",
       "      <td>-0.305447</td>\n",
       "      <td>-0.295557</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49077</th>\n",
       "      <td>-0.296164</td>\n",
       "      <td>-0.013886</td>\n",
       "      <td>-0.041915</td>\n",
       "      <td>-0.019701</td>\n",
       "      <td>-0.021452</td>\n",
       "      <td>-0.650602</td>\n",
       "      <td>-0.459452</td>\n",
       "      <td>-0.807009</td>\n",
       "      <td>-0.601549</td>\n",
       "      <td>-0.704871</td>\n",
       "      <td>...</td>\n",
       "      <td>2.859529</td>\n",
       "      <td>-0.069433</td>\n",
       "      <td>-0.057395</td>\n",
       "      <td>-0.079483</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.302176</td>\n",
       "      <td>-0.090334</td>\n",
       "      <td>-0.305447</td>\n",
       "      <td>-0.295557</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>3.251156</td>\n",
       "      <td>-0.013886</td>\n",
       "      <td>-0.041915</td>\n",
       "      <td>-0.019701</td>\n",
       "      <td>-0.021452</td>\n",
       "      <td>-0.650602</td>\n",
       "      <td>-0.459452</td>\n",
       "      <td>-0.807009</td>\n",
       "      <td>-0.601549</td>\n",
       "      <td>-0.704871</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.337249</td>\n",
       "      <td>-0.069433</td>\n",
       "      <td>-0.057395</td>\n",
       "      <td>-0.079483</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>3.244164</td>\n",
       "      <td>-0.090311</td>\n",
       "      <td>3.186388</td>\n",
       "      <td>3.278090</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469282</th>\n",
       "      <td>-0.394794</td>\n",
       "      <td>-0.015187</td>\n",
       "      <td>-0.035153</td>\n",
       "      <td>-0.019064</td>\n",
       "      <td>-0.021227</td>\n",
       "      <td>-0.546926</td>\n",
       "      <td>0.869308</td>\n",
       "      <td>-0.293698</td>\n",
       "      <td>-0.601549</td>\n",
       "      <td>-0.608258</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.297894</td>\n",
       "      <td>-0.069433</td>\n",
       "      <td>-0.057395</td>\n",
       "      <td>-0.079483</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.302176</td>\n",
       "      <td>-0.090334</td>\n",
       "      <td>-0.305447</td>\n",
       "      <td>-0.295557</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504000</th>\n",
       "      <td>-0.349719</td>\n",
       "      <td>-0.010633</td>\n",
       "      <td>0.005416</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>-0.014058</td>\n",
       "      <td>1.542807</td>\n",
       "      <td>-0.459452</td>\n",
       "      <td>1.494869</td>\n",
       "      <td>1.335137</td>\n",
       "      <td>1.656092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261140</td>\n",
       "      <td>-0.069433</td>\n",
       "      <td>-0.057395</td>\n",
       "      <td>-0.079483</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.302176</td>\n",
       "      <td>-0.090334</td>\n",
       "      <td>-0.305447</td>\n",
       "      <td>-0.295557</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420640</th>\n",
       "      <td>-0.394225</td>\n",
       "      <td>-0.015187</td>\n",
       "      <td>-0.035153</td>\n",
       "      <td>-0.019084</td>\n",
       "      <td>-0.021045</td>\n",
       "      <td>-0.550165</td>\n",
       "      <td>0.827784</td>\n",
       "      <td>-0.309739</td>\n",
       "      <td>-0.601549</td>\n",
       "      <td>-0.529761</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.297894</td>\n",
       "      <td>-0.069433</td>\n",
       "      <td>-0.057395</td>\n",
       "      <td>-0.079483</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.302176</td>\n",
       "      <td>-0.090334</td>\n",
       "      <td>-0.305447</td>\n",
       "      <td>-0.295557</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490836</th>\n",
       "      <td>0.065098</td>\n",
       "      <td>-0.008681</td>\n",
       "      <td>0.012178</td>\n",
       "      <td>-0.006285</td>\n",
       "      <td>0.006223</td>\n",
       "      <td>1.024423</td>\n",
       "      <td>-0.459452</td>\n",
       "      <td>0.175864</td>\n",
       "      <td>0.721351</td>\n",
       "      <td>2.233753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261140</td>\n",
       "      <td>1.127449</td>\n",
       "      <td>-0.057395</td>\n",
       "      <td>0.827703</td>\n",
       "      <td>1.360008</td>\n",
       "      <td>0.076554</td>\n",
       "      <td>-0.090334</td>\n",
       "      <td>0.067462</td>\n",
       "      <td>0.086090</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537625</th>\n",
       "      <td>-0.228941</td>\n",
       "      <td>-0.013886</td>\n",
       "      <td>-0.035153</td>\n",
       "      <td>-0.019701</td>\n",
       "      <td>-0.021452</td>\n",
       "      <td>-0.650602</td>\n",
       "      <td>-0.459452</td>\n",
       "      <td>-0.807009</td>\n",
       "      <td>-0.601549</td>\n",
       "      <td>-0.704871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261140</td>\n",
       "      <td>-0.069433</td>\n",
       "      <td>-0.057395</td>\n",
       "      <td>-0.079483</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.302176</td>\n",
       "      <td>-0.090334</td>\n",
       "      <td>-0.305447</td>\n",
       "      <td>-0.295557</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>857189 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Flow Duration  Tot Fwd Pkts  Tot Bwd Pkts  TotLen Fwd Pkts  \\\n",
       "50387       -0.296443     -0.013886     -0.041915        -0.019701   \n",
       "39981       -0.296171     -0.013886     -0.041915        -0.019701   \n",
       "32972       -0.394804     -0.015187     -0.028392        -0.014963   \n",
       "49077       -0.296164     -0.013886     -0.041915        -0.019701   \n",
       "357          3.251156     -0.013886     -0.041915        -0.019701   \n",
       "...               ...           ...           ...              ...   \n",
       "469282      -0.394794     -0.015187     -0.035153        -0.019064   \n",
       "504000      -0.349719     -0.010633      0.005416         0.003150   \n",
       "420640      -0.394225     -0.015187     -0.035153        -0.019084   \n",
       "490836       0.065098     -0.008681      0.012178        -0.006285   \n",
       "537625      -0.228941     -0.013886     -0.035153        -0.019701   \n",
       "\n",
       "        TotLen Bwd Pkts  Fwd Pkt Len Max  Fwd Pkt Len Min  Fwd Pkt Len Mean  \\\n",
       "50387         -0.021452        -0.650602        -0.459452         -0.807009   \n",
       "39981         -0.021452        -0.650602        -0.459452         -0.807009   \n",
       "32972         -0.019039         0.120493         9.423202          3.010740   \n",
       "49077         -0.021452        -0.650602        -0.459452         -0.807009   \n",
       "357           -0.021452        -0.650602        -0.459452         -0.807009   \n",
       "...                 ...              ...              ...               ...   \n",
       "469282        -0.021227        -0.546926         0.869308         -0.293698   \n",
       "504000        -0.014058         1.542807        -0.459452          1.494869   \n",
       "420640        -0.021045        -0.550165         0.827784         -0.309739   \n",
       "490836         0.006223         1.024423        -0.459452          0.175864   \n",
       "537625        -0.021452        -0.650602        -0.459452         -0.807009   \n",
       "\n",
       "        Fwd Pkt Len Std  Bwd Pkt Len Max  ...  Fwd Seg Size Min  Active Mean  \\\n",
       "50387         -0.601549        -0.704871  ...          2.859529    -0.069433   \n",
       "39981         -0.601549        -0.704871  ...          2.859529    -0.069433   \n",
       "32972         -0.601549         0.333711  ...          1.820173    -0.069433   \n",
       "49077         -0.601549        -0.704871  ...          2.859529    -0.069433   \n",
       "357           -0.601549        -0.704871  ...         -2.337249    -0.069433   \n",
       "...                 ...              ...  ...               ...          ...   \n",
       "469282        -0.601549        -0.608258  ...         -1.297894    -0.069433   \n",
       "504000         1.335137         1.656092  ...          0.261140    -0.069433   \n",
       "420640        -0.601549        -0.529761  ...         -1.297894    -0.069433   \n",
       "490836         0.721351         2.233753  ...          0.261140     1.127449   \n",
       "537625        -0.601549        -0.704871  ...          0.261140    -0.069433   \n",
       "\n",
       "        Active Std  Active Max  Active Min  Idle Mean  Idle Std  Idle Max  \\\n",
       "50387    -0.057395   -0.079483   -0.054963  -0.302176 -0.090334 -0.305447   \n",
       "39981    -0.057395   -0.079483   -0.054963  -0.302176 -0.090334 -0.305447   \n",
       "32972    -0.057395   -0.079483   -0.054963  -0.302176 -0.090334 -0.305447   \n",
       "49077    -0.057395   -0.079483   -0.054963  -0.302176 -0.090334 -0.305447   \n",
       "357      -0.057395   -0.079483   -0.054963   3.244164 -0.090311  3.186388   \n",
       "...            ...         ...         ...        ...       ...       ...   \n",
       "469282   -0.057395   -0.079483   -0.054963  -0.302176 -0.090334 -0.305447   \n",
       "504000   -0.057395   -0.079483   -0.054963  -0.302176 -0.090334 -0.305447   \n",
       "420640   -0.057395   -0.079483   -0.054963  -0.302176 -0.090334 -0.305447   \n",
       "490836   -0.057395    0.827703    1.360008   0.076554 -0.090334  0.067462   \n",
       "537625   -0.057395   -0.079483   -0.054963  -0.302176 -0.090334 -0.305447   \n",
       "\n",
       "        Idle Min  Label  \n",
       "50387  -0.295557     10  \n",
       "39981  -0.295557     10  \n",
       "32972  -0.295557     10  \n",
       "49077  -0.295557     10  \n",
       "357     3.278090      2  \n",
       "...          ...    ...  \n",
       "469282 -0.295557     12  \n",
       "504000 -0.295557     12  \n",
       "420640 -0.295557     12  \n",
       "490836  0.086090     12  \n",
       "537625 -0.295557     12  \n",
       "\n",
       "[857189 rows x 77 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9a6aef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(group):\n",
    "    frac = 0.09\n",
    "    return group.sample(frac=frac, replace=True)\n",
    "\n",
    "\n",
    "sample_df = result.groupby('Label', group_keys=False).apply(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e6b307d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>TotLen Fwd Pkts</th>\n",
       "      <th>TotLen Bwd Pkts</th>\n",
       "      <th>Fwd Pkt Len Max</th>\n",
       "      <th>Fwd Pkt Len Min</th>\n",
       "      <th>Fwd Pkt Len Mean</th>\n",
       "      <th>Fwd Pkt Len Std</th>\n",
       "      <th>Bwd Pkt Len Max</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6404770</th>\n",
       "      <td>0.585900</td>\n",
       "      <td>-0.008681</td>\n",
       "      <td>0.032463</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>3.402506</td>\n",
       "      <td>-0.459452</td>\n",
       "      <td>1.478099</td>\n",
       "      <td>2.566517</td>\n",
       "      <td>2.233753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261140</td>\n",
       "      <td>-0.041288</td>\n",
       "      <td>0.010712</td>\n",
       "      <td>-0.022290</td>\n",
       "      <td>-0.049706</td>\n",
       "      <td>0.328468</td>\n",
       "      <td>-0.086003</td>\n",
       "      <td>0.315767</td>\n",
       "      <td>0.339418</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5129635</th>\n",
       "      <td>-0.394813</td>\n",
       "      <td>-0.015187</td>\n",
       "      <td>-0.035153</td>\n",
       "      <td>-0.019701</td>\n",
       "      <td>-0.021452</td>\n",
       "      <td>-0.650602</td>\n",
       "      <td>-0.459452</td>\n",
       "      <td>-0.807009</td>\n",
       "      <td>-0.601549</td>\n",
       "      <td>-0.704871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261140</td>\n",
       "      <td>-0.069433</td>\n",
       "      <td>-0.057395</td>\n",
       "      <td>-0.079483</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.302176</td>\n",
       "      <td>-0.090334</td>\n",
       "      <td>-0.305447</td>\n",
       "      <td>-0.295557</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6235035</th>\n",
       "      <td>-0.389545</td>\n",
       "      <td>-0.013886</td>\n",
       "      <td>-0.035153</td>\n",
       "      <td>-0.019701</td>\n",
       "      <td>-0.021452</td>\n",
       "      <td>-0.650602</td>\n",
       "      <td>-0.459452</td>\n",
       "      <td>-0.807009</td>\n",
       "      <td>-0.601549</td>\n",
       "      <td>-0.704871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261140</td>\n",
       "      <td>-0.069433</td>\n",
       "      <td>-0.057395</td>\n",
       "      <td>-0.079483</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.302176</td>\n",
       "      <td>-0.090334</td>\n",
       "      <td>-0.305447</td>\n",
       "      <td>-0.295557</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4930595</th>\n",
       "      <td>-0.394809</td>\n",
       "      <td>-0.013886</td>\n",
       "      <td>-0.041915</td>\n",
       "      <td>-0.019084</td>\n",
       "      <td>-0.021452</td>\n",
       "      <td>-0.550165</td>\n",
       "      <td>-0.459452</td>\n",
       "      <td>-0.641252</td>\n",
       "      <td>-0.449607</td>\n",
       "      <td>-0.704871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261140</td>\n",
       "      <td>-0.069433</td>\n",
       "      <td>-0.057395</td>\n",
       "      <td>-0.079483</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.302176</td>\n",
       "      <td>-0.090334</td>\n",
       "      <td>-0.305447</td>\n",
       "      <td>-0.295557</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299427</th>\n",
       "      <td>3.421725</td>\n",
       "      <td>-0.005428</td>\n",
       "      <td>0.045986</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>-0.002999</td>\n",
       "      <td>0.483361</td>\n",
       "      <td>-0.459452</td>\n",
       "      <td>0.191541</td>\n",
       "      <td>0.242479</td>\n",
       "      <td>2.173370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261140</td>\n",
       "      <td>0.096259</td>\n",
       "      <td>0.144986</td>\n",
       "      <td>0.111360</td>\n",
       "      <td>0.039139</td>\n",
       "      <td>3.377080</td>\n",
       "      <td>0.312963</td>\n",
       "      <td>3.346585</td>\n",
       "      <td>3.382018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270611</th>\n",
       "      <td>-0.384595</td>\n",
       "      <td>-0.001525</td>\n",
       "      <td>0.106841</td>\n",
       "      <td>0.018994</td>\n",
       "      <td>-0.008989</td>\n",
       "      <td>1.422931</td>\n",
       "      <td>-0.459452</td>\n",
       "      <td>0.610429</td>\n",
       "      <td>0.568877</td>\n",
       "      <td>1.259579</td>\n",
       "      <td>...</td>\n",
       "      <td>1.820173</td>\n",
       "      <td>-0.069433</td>\n",
       "      <td>-0.057395</td>\n",
       "      <td>-0.079483</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.302176</td>\n",
       "      <td>-0.090334</td>\n",
       "      <td>-0.305447</td>\n",
       "      <td>-0.295557</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337970</th>\n",
       "      <td>-0.394814</td>\n",
       "      <td>-0.015187</td>\n",
       "      <td>-0.035153</td>\n",
       "      <td>-0.019701</td>\n",
       "      <td>-0.021452</td>\n",
       "      <td>-0.650602</td>\n",
       "      <td>-0.459452</td>\n",
       "      <td>-0.807009</td>\n",
       "      <td>-0.601549</td>\n",
       "      <td>-0.704871</td>\n",
       "      <td>...</td>\n",
       "      <td>1.820173</td>\n",
       "      <td>-0.069433</td>\n",
       "      <td>-0.057395</td>\n",
       "      <td>-0.079483</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.302176</td>\n",
       "      <td>-0.090334</td>\n",
       "      <td>-0.305447</td>\n",
       "      <td>-0.295557</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320610</th>\n",
       "      <td>-0.394814</td>\n",
       "      <td>-0.015187</td>\n",
       "      <td>-0.035153</td>\n",
       "      <td>-0.019701</td>\n",
       "      <td>-0.021452</td>\n",
       "      <td>-0.650602</td>\n",
       "      <td>-0.459452</td>\n",
       "      <td>-0.807009</td>\n",
       "      <td>-0.601549</td>\n",
       "      <td>-0.704871</td>\n",
       "      <td>...</td>\n",
       "      <td>1.820173</td>\n",
       "      <td>-0.069433</td>\n",
       "      <td>-0.057395</td>\n",
       "      <td>-0.079483</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.302176</td>\n",
       "      <td>-0.090334</td>\n",
       "      <td>-0.305447</td>\n",
       "      <td>-0.295557</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322104</th>\n",
       "      <td>-0.382990</td>\n",
       "      <td>-0.002176</td>\n",
       "      <td>0.106841</td>\n",
       "      <td>0.018676</td>\n",
       "      <td>-0.008989</td>\n",
       "      <td>1.422931</td>\n",
       "      <td>-0.459452</td>\n",
       "      <td>0.665704</td>\n",
       "      <td>0.584855</td>\n",
       "      <td>1.259579</td>\n",
       "      <td>...</td>\n",
       "      <td>1.820173</td>\n",
       "      <td>-0.069433</td>\n",
       "      <td>-0.057395</td>\n",
       "      <td>-0.079483</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.302176</td>\n",
       "      <td>-0.090334</td>\n",
       "      <td>-0.305447</td>\n",
       "      <td>-0.295557</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248621</th>\n",
       "      <td>-0.383242</td>\n",
       "      <td>-0.001525</td>\n",
       "      <td>0.106841</td>\n",
       "      <td>0.018676</td>\n",
       "      <td>-0.008989</td>\n",
       "      <td>1.422931</td>\n",
       "      <td>-0.459452</td>\n",
       "      <td>0.598763</td>\n",
       "      <td>0.568126</td>\n",
       "      <td>1.259579</td>\n",
       "      <td>...</td>\n",
       "      <td>1.820173</td>\n",
       "      <td>-0.069433</td>\n",
       "      <td>-0.057395</td>\n",
       "      <td>-0.079483</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.302176</td>\n",
       "      <td>-0.090334</td>\n",
       "      <td>-0.305447</td>\n",
       "      <td>-0.295557</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77147 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Flow Duration  Tot Fwd Pkts  Tot Bwd Pkts  TotLen Fwd Pkts  \\\n",
       "6404770       0.585900     -0.008681      0.032463         0.011490   \n",
       "5129635      -0.394813     -0.015187     -0.035153        -0.019701   \n",
       "6235035      -0.389545     -0.013886     -0.035153        -0.019701   \n",
       "4930595      -0.394809     -0.013886     -0.041915        -0.019084   \n",
       "299427        3.421725     -0.005428      0.045986         0.000125   \n",
       "...                ...           ...           ...              ...   \n",
       "270611       -0.384595     -0.001525      0.106841         0.018994   \n",
       "337970       -0.394814     -0.015187     -0.035153        -0.019701   \n",
       "320610       -0.394814     -0.015187     -0.035153        -0.019701   \n",
       "322104       -0.382990     -0.002176      0.106841         0.018676   \n",
       "248621       -0.383242     -0.001525      0.106841         0.018676   \n",
       "\n",
       "         TotLen Bwd Pkts  Fwd Pkt Len Max  Fwd Pkt Len Min  Fwd Pkt Len Mean  \\\n",
       "6404770         0.000106         3.402506        -0.459452          1.478099   \n",
       "5129635        -0.021452        -0.650602        -0.459452         -0.807009   \n",
       "6235035        -0.021452        -0.650602        -0.459452         -0.807009   \n",
       "4930595        -0.021452        -0.550165        -0.459452         -0.641252   \n",
       "299427         -0.002999         0.483361        -0.459452          0.191541   \n",
       "...                  ...              ...              ...               ...   \n",
       "270611         -0.008989         1.422931        -0.459452          0.610429   \n",
       "337970         -0.021452        -0.650602        -0.459452         -0.807009   \n",
       "320610         -0.021452        -0.650602        -0.459452         -0.807009   \n",
       "322104         -0.008989         1.422931        -0.459452          0.665704   \n",
       "248621         -0.008989         1.422931        -0.459452          0.598763   \n",
       "\n",
       "         Fwd Pkt Len Std  Bwd Pkt Len Max  ...  Fwd Seg Size Min  Active Mean  \\\n",
       "6404770         2.566517         2.233753  ...          0.261140    -0.041288   \n",
       "5129635        -0.601549        -0.704871  ...          0.261140    -0.069433   \n",
       "6235035        -0.601549        -0.704871  ...          0.261140    -0.069433   \n",
       "4930595        -0.449607        -0.704871  ...          0.261140    -0.069433   \n",
       "299427          0.242479         2.173370  ...          0.261140     0.096259   \n",
       "...                  ...              ...  ...               ...          ...   \n",
       "270611          0.568877         1.259579  ...          1.820173    -0.069433   \n",
       "337970         -0.601549        -0.704871  ...          1.820173    -0.069433   \n",
       "320610         -0.601549        -0.704871  ...          1.820173    -0.069433   \n",
       "322104          0.584855         1.259579  ...          1.820173    -0.069433   \n",
       "248621          0.568126         1.259579  ...          1.820173    -0.069433   \n",
       "\n",
       "         Active Std  Active Max  Active Min  Idle Mean  Idle Std  Idle Max  \\\n",
       "6404770    0.010712   -0.022290   -0.049706   0.328468 -0.086003  0.315767   \n",
       "5129635   -0.057395   -0.079483   -0.054963  -0.302176 -0.090334 -0.305447   \n",
       "6235035   -0.057395   -0.079483   -0.054963  -0.302176 -0.090334 -0.305447   \n",
       "4930595   -0.057395   -0.079483   -0.054963  -0.302176 -0.090334 -0.305447   \n",
       "299427     0.144986    0.111360    0.039139   3.377080  0.312963  3.346585   \n",
       "...             ...         ...         ...        ...       ...       ...   \n",
       "270611    -0.057395   -0.079483   -0.054963  -0.302176 -0.090334 -0.305447   \n",
       "337970    -0.057395   -0.079483   -0.054963  -0.302176 -0.090334 -0.305447   \n",
       "320610    -0.057395   -0.079483   -0.054963  -0.302176 -0.090334 -0.305447   \n",
       "322104    -0.057395   -0.079483   -0.054963  -0.302176 -0.090334 -0.305447   \n",
       "248621    -0.057395   -0.079483   -0.054963  -0.302176 -0.090334 -0.305447   \n",
       "\n",
       "         Idle Min  Label  \n",
       "6404770  0.339418      0  \n",
       "5129635 -0.295557      0  \n",
       "6235035 -0.295557      0  \n",
       "4930595 -0.295557      0  \n",
       "299427   3.382018      0  \n",
       "...           ...    ...  \n",
       "270611  -0.295557     14  \n",
       "337970  -0.295557     14  \n",
       "320610  -0.295557     14  \n",
       "322104  -0.295557     14  \n",
       "248621  -0.295557     14  \n",
       "\n",
       "[77147 rows x 77 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2301e43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv('./CICIDS_2018/CICIDS2018_cleaned.csv', index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1181b80",
   "metadata": {},
   "source": [
    "## Read the cleaned CICIDS2018 dataset\n",
    "Due to the large size of this dataset, the sampled subsets of CICIDS2018 is used. The subsets are in the \"CICIDS_2018\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd0c49cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read dataset\n",
    "df = pd.read_csv('./CICIDS_2018/CICIDS2018_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1f7e216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts',\n",
       "       'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min',\n",
       "       'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Bwd Pkt Len Max',\n",
       "       'Bwd Pkt Len Min', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Flow Byts/s',\n",
       "       'Flow Pkts/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max',\n",
       "       'Flow IAT Min', 'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Std',\n",
       "       'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Tot', 'Bwd IAT Mean',\n",
       "       'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags',\n",
       "       'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Len',\n",
       "       'Bwd Header Len', 'Fwd Pkts/s', 'Bwd Pkts/s', 'Pkt Len Min',\n",
       "       'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Std', 'Pkt Len Var',\n",
       "       'FIN Flag Cnt', 'SYN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt',\n",
       "       'ACK Flag Cnt', 'URG Flag Cnt', 'CWE Flag Count', 'ECE Flag Cnt',\n",
       "       'Down/Up Ratio', 'Pkt Size Avg', 'Fwd Seg Size Avg', 'Bwd Seg Size Avg',\n",
       "       'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg',\n",
       "       'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg',\n",
       "       'Subflow Fwd Pkts', 'Subflow Fwd Byts', 'Subflow Bwd Pkts',\n",
       "       'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts',\n",
       "       'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std',\n",
       "       'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max',\n",
       "       'Idle Min', 'Label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc80acf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     60674\n",
       "10     3390\n",
       "4      3087\n",
       "6      2593\n",
       "8      2079\n",
       "1      1270\n",
       "11      870\n",
       "14      844\n",
       "12      729\n",
       "9       629\n",
       "5       495\n",
       "2       234\n",
       "7       187\n",
       "3        56\n",
       "13       10\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "55dcbb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df > 1e308] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3f40af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Label'], axis=1).values\n",
    "y = df.iloc[:, -1].values.reshape(-1, 1)\n",
    "y = np.ravel(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f66f93fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    train_size=0.7,\n",
    "    test_size=0.3,\n",
    "    random_state=0,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6f4141",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "### Feature selection by information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "480ea826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "importances = mutual_info_classif(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff20471b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.79967614e-01 2.66691682e-01 2.65798264e-01 4.72653877e-01\n",
      " 3.40347465e-01 4.59568835e-01 1.38610981e-01 4.55225701e-01\n",
      " 3.01630073e-01 3.36519207e-01 7.24348189e-02 3.43978571e-01\n",
      " 2.51883992e-01 0.00000000e+00 0.00000000e+00 5.63024991e-01\n",
      " 3.59914073e-01 5.84242730e-01 3.99719146e-01 5.42884777e-01\n",
      " 5.32619380e-01 3.04035048e-01 5.44625204e-01 4.35434955e-01\n",
      " 2.71470018e-01 2.61339189e-01 2.21318534e-01 2.70875629e-01\n",
      " 2.33912796e-01 2.87995161e-02 8.58382972e-04 0.00000000e+00\n",
      " 0.00000000e+00 5.30491982e-01 3.84157826e-01 5.58920986e-01\n",
      " 4.36992236e-01 9.64284990e-02 4.59370628e-01 4.50418948e-01\n",
      " 4.24288171e-01 4.24268292e-01 4.56444479e-03 3.09636572e-02\n",
      " 4.23781197e-02 4.91333029e-02 6.26303327e-02 1.91706061e-02\n",
      " 1.70561581e-04 4.36696891e-02 4.55806303e-02 4.49480782e-01\n",
      " 4.52736098e-01 3.40346185e-01 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.03354974e-03 9.49608405e-04\n",
      " 2.69377255e-01 4.69750304e-01 2.61190831e-01 3.39600081e-01\n",
      " 6.85285317e-01 3.38229843e-01 1.88656583e-01 3.56568975e-01\n",
      " 1.25454740e-01 6.82953318e-02 1.24707890e-01 1.22674050e-01\n",
      " 1.63904618e-01 8.36149053e-02 1.65559056e-01 1.66351001e-01]\n"
     ]
    }
   ],
   "source": [
    "print(importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "85d9e13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the sum of importance scores\n",
    "f_list = sorted(\n",
    "    zip(map(lambda x: round(x, 4), importances),\n",
    "    features), reverse=True)\n",
    "Sum = 0\n",
    "fs = []\n",
    "for i in range(0, len(f_list)):\n",
    "    Sum = Sum + f_list[i][0]\n",
    "    fs.append(f_list[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d4c906c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the important features from top to bottom until the accumulated importance reaches 95%\n",
    "f_list2 = sorted(\n",
    "    zip(map(lambda x: round(x, 4), importances/Sum), features), reverse=True)\n",
    "Sum2 = 0\n",
    "fs = []\n",
    "for i in range(0, len(f_list2)):\n",
    "    Sum2 = Sum2 + f_list2[i][0]\n",
    "    fs.append(f_list2[i][1])\n",
    "    if Sum2 >= 0.95:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8034fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fs = df[fs].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9a69ed7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.03566032  0.22436237  0.58590017 ...  0.32846848 -0.45945226\n",
      "  -0.04128834]\n",
      " [-0.52968658 -0.35884169 -0.39481337 ... -0.30217581 -0.45945226\n",
      "  -0.06943273]\n",
      " [-0.03566032 -0.34938003 -0.38954514 ... -0.30217581 -0.45945226\n",
      "  -0.06943273]\n",
      " ...\n",
      " [-0.52635399 -0.3588421  -0.3948136  ... -0.30217581 -0.45945226\n",
      "  -0.06943273]\n",
      " [ 1.11784934 -0.3511747  -0.38299045 ... -0.30217581 -0.45945226\n",
      "  -0.06943273]\n",
      " [ 1.11784934 -0.35281796 -0.38324211 ... -0.30217581 -0.45945226\n",
      "  -0.06943273]]\n"
     ]
    }
   ],
   "source": [
    "print(X_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "436a1da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77147, 49)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cf69e1",
   "metadata": {},
   "source": [
    "### Feature selection by Fast Correlation Based Filter (FCBF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "026871c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FCBF_module import FCBF, FCBFK, FCBFiP, get_i\n",
    "fcbf = FCBFK(k=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a94d495",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fss = fcbf.fit_transform(X_fs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9b48f5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77147, 21)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fss.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272bc865",
   "metadata": {},
   "source": [
    "### Re-split train & test sets after feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5856f95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_fss, y, stratify=y, train_size=0.7, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c3da8aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54002, 21)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0c16d4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     42471\n",
       "10     2373\n",
       "4      2161\n",
       "6      1815\n",
       "8      1455\n",
       "1       889\n",
       "11      609\n",
       "14      591\n",
       "12      510\n",
       "9       440\n",
       "5       347\n",
       "2       164\n",
       "7       131\n",
       "3        39\n",
       "13        7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbf2772",
   "metadata": {},
   "source": [
    "### SMOTE to solve class-imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8dc707df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(n_jobs=-1, sampling_strategy={\n",
    "    1:889*3,\n",
    "    11:609*3,\n",
    "    14:591*7,\n",
    "    12:510*12,\n",
    "    9:440*14,\n",
    "    5:347*11,\n",
    "    2:161*17,\n",
    "    7:131*17,\n",
    "    3:38*70,\n",
    "    13:6*110\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c9e16580",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "16fbc817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     42471\n",
       "9      6160\n",
       "12     6120\n",
       "14     4137\n",
       "5      3817\n",
       "2      2737\n",
       "1      2667\n",
       "3      2660\n",
       "10     2373\n",
       "7      2227\n",
       "4      2161\n",
       "11     1827\n",
       "6      1815\n",
       "8      1455\n",
       "13      660\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d1f07f",
   "metadata": {},
   "source": [
    "## Machine learning model training\n",
    "### Training decision tree, random forest, extra trees, XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dafb89",
   "metadata": {},
   "source": [
    "#### Apply decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9048915a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of DT: 0.9684597105206308\n",
      "Precision of DT: 0.9782721298063981\n",
      "Recall of DT: 0.9684597105206308\n",
      "F1-score of DT: 0.9718564665939484\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98     18203\n",
      "           1       0.98      0.99      0.99       381\n",
      "           2       0.97      1.00      0.99        70\n",
      "           3       1.00      1.00      1.00        17\n",
      "           4       1.00      1.00      1.00       926\n",
      "           5       0.99      1.00      1.00       148\n",
      "           6       0.99      1.00      1.00       778\n",
      "           7       0.98      0.95      0.96        56\n",
      "           8       0.99      1.00      1.00       624\n",
      "           9       0.56      0.96      0.71       189\n",
      "          10       0.99      1.00      1.00      1017\n",
      "          11       0.95      0.47      0.63       261\n",
      "          12       0.10      0.20      0.14       219\n",
      "          13       0.75      1.00      0.86         3\n",
      "          14       1.00      1.00      1.00       253\n",
      "\n",
      "    accuracy                           0.97     23145\n",
      "   macro avg       0.88      0.90      0.88     23145\n",
      "weighted avg       0.98      0.97      0.97     23145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "dt.fit(X_train, y_train)\n",
    "dt_score = dt.score(X_test, y_test)\n",
    "y_predict = dt.predict(X_test)\n",
    "y_true = y_test\n",
    "print('Accuracy of DT: ' + str(dt_score))\n",
    "precision, recall, fscore, none = precision_recall_fscore_support(\n",
    "    y_true, y_predict, average='weighted')\n",
    "print('Precision of DT: '+(str(precision)))\n",
    "print('Recall of DT: '+(str(recall)))\n",
    "print('F1-score of DT: '+(str(fscore)))\n",
    "print(classification_report(y_true, y_predict))\n",
    "cm = confusion_matrix(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f205f4af",
   "metadata": {},
   "source": [
    "#### Hyperparameter optimization (HPO) of decision tree using Bayesian optimization with tree-based Parzen estimator (BO-TPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b512794d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:34<00:00,  2.24trial/s, best loss: -0.9719161806005617]\n",
      "Decision tree: Hyperopt estimated optimum {'criterion': 1, 'max_depth': 25.0, 'max_features': 6.0, 'min_samples_leaf': 1.0, 'min_samples_split': 8.0}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter optimization of decision tree\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK\n",
    "# Define the objective function\n",
    "def objective(params):\n",
    "    params = {\n",
    "        \"min_samples_leaf\": int(params['min_samples_leaf']),\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        \"min_samples_split\": int(params['min_samples_split']),\n",
    "        'max_features': int(params['max_features']),\n",
    "        \"criterion\": str(params['criterion'])\n",
    "    }\n",
    "    clf = DecisionTreeClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "\n",
    "    return {'loss': -score, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "# Define the hyperparameter configuration space\n",
    "space = {\n",
    "    \"min_samples_leaf\": hp.quniform('min_samples_leaf', 1, 11, 1),\n",
    "    'max_depth': hp.quniform('max_depth', 5, 50, 1),\n",
    "    \"min_samples_split\": hp.quniform('min_samples_split', 2, 11, 1),\n",
    "    \"max_features\": hp.quniform('max_features', 1, 21, 1),\n",
    "    \"criterion\": hp.choice('criterion', ['gini', 'entropy'])\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=77)\n",
    "print(\"Decision tree: Hyperopt estimated optimum {}\".format(best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8f1caf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of DT: 0.9720025923525599\n",
      "Precision of DT: 0.9782357336719879\n",
      "Recall of DT: 0.9720025923525599\n",
      "F1-score of DT: 0.973721467384721\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99     18203\n",
      "           1       0.98      0.99      0.98       381\n",
      "           2       0.96      1.00      0.98        70\n",
      "           3       1.00      1.00      1.00        17\n",
      "           4       1.00      1.00      1.00       926\n",
      "           5       0.99      1.00      1.00       148\n",
      "           6       1.00      1.00      1.00       778\n",
      "           7       0.96      0.89      0.93        56\n",
      "           8       1.00      1.00      1.00       624\n",
      "           9       0.56      0.96      0.71       189\n",
      "          10       1.00      1.00      1.00      1017\n",
      "          11       0.94      0.46      0.62       261\n",
      "          12       0.12      0.19      0.15       219\n",
      "          13       1.00      1.00      1.00         3\n",
      "          14       1.00      1.00      1.00       253\n",
      "\n",
      "    accuracy                           0.97     23145\n",
      "   macro avg       0.90      0.90      0.89     23145\n",
      "weighted avg       0.98      0.97      0.97     23145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_hpo = DecisionTreeClassifier(\n",
    "    min_samples_leaf=1, max_depth=16, min_samples_split=11, max_features=20, criterion='entropy')\n",
    "dt_hpo.fit(X_train, y_train)\n",
    "dt_score = dt_hpo.score(X_test, y_test)\n",
    "y_predict = dt_hpo.predict(X_test)\n",
    "y_true = y_test\n",
    "print('Accuracy of DT: ' + str(dt_score))\n",
    "precision, recall, fscore, none = precision_recall_fscore_support(\n",
    "    y_true, y_predict, average='weighted')\n",
    "print('Precision of DT: '+(str(precision)))\n",
    "print('Recall of DT: '+(str(recall)))\n",
    "print('F1-score of DT: '+(str(fscore)))\n",
    "print(classification_report(y_true, y_predict))\n",
    "cm = confusion_matrix(y_true, y_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f9961e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train = dt_hpo.predict(X_train)\n",
    "dt_test = dt_hpo.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b991d72",
   "metadata": {},
   "source": [
    "### Apply RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "23c27d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RF: 0.9766256210844675\n",
      "Precision of RF: 0.9792517959112764\n",
      "Recall of RF: 0.9766256210844675\n",
      "F1-score of RF: 0.9759718240312625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     18203\n",
      "           1       0.98      0.99      0.98       381\n",
      "           2       1.00      1.00      1.00        70\n",
      "           3       0.94      1.00      0.97        17\n",
      "           4       0.99      1.00      1.00       926\n",
      "           5       0.99      1.00      1.00       148\n",
      "           6       0.99      1.00      1.00       778\n",
      "           7       0.98      0.96      0.97        56\n",
      "           8       1.00      1.00      1.00       624\n",
      "           9       0.54      0.99      0.70       189\n",
      "          10       1.00      1.00      1.00      1017\n",
      "          11       0.99      0.40      0.57       261\n",
      "          12       0.20      0.19      0.19       219\n",
      "          13       1.00      1.00      1.00         3\n",
      "          14       1.00      1.00      1.00       253\n",
      "\n",
      "    accuracy                           0.98     23145\n",
      "   macro avg       0.91      0.90      0.89     23145\n",
      "weighted avg       0.98      0.98      0.98     23145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_score = rf.score(X_test, y_test)\n",
    "y_predict = rf.predict(X_test)\n",
    "y_true = y_test\n",
    "print('Accuracy of RF: ' + str(rf_score))\n",
    "precision, recall, fscore, none = precision_recall_fscore_support(\n",
    "    y_true, y_predict, average='weighted')\n",
    "print('Precision of RF: '+(str(precision)))\n",
    "print('Recall of RF: '+(str(recall)))\n",
    "print('F1-score of RF: '+(str(fscore)))\n",
    "print(classification_report(y_true, y_predict))\n",
    "cm = confusion_matrix(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf06b30c",
   "metadata": {},
   "source": [
    "#### Hyperparameter optimization (HPO) of random forest using Bayesian optimization with tree-based Parzen estimator (BO-TPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "96133dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [11:46<00:00, 33.65s/trial, best loss: -0.9791747677684165]\n",
      "Random Forest: Hyperopt estimated optimum {'criterion': 0, 'max_depth': 37.0, 'max_features': 14.0, 'min_samples_leaf': 4.0, 'min_samples_split': 5.0, 'n_estimators': 107.0}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter optimization of random forest\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK\n",
    "# Define the objective function\n",
    "\n",
    "def objective(params):\n",
    "    params = {\n",
    "        'n_estimators': int(params['n_estimators']),\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'max_features': int(params['max_features']),\n",
    "        \"min_samples_split\": int(params['min_samples_split']),\n",
    "        \"min_samples_leaf\": int(params['min_samples_leaf']),\n",
    "        \"criterion\": str(params['criterion'])\n",
    "    }\n",
    "    clf = RandomForestClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "\n",
    "    return {'loss': -score, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "# Define the hyperparameter configuration space\n",
    "space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 10, 200, 1),\n",
    "    'max_depth': hp.quniform('max_depth', 5, 50, 1),\n",
    "    \"max_features\": hp.quniform('max_features', 1, 21, 1),\n",
    "    \"min_samples_split\": hp.quniform('min_samples_split', 2, 11, 1),\n",
    "    \"min_samples_leaf\": hp.quniform('min_samples_leaf', 2, 11, 1),\n",
    "    \"criterion\": hp.choice('criterion', ['gini', 'entropy'])\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=22)\n",
    "print(\"Random Forest: Hyperopt estimated optimum {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c0a2a7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RF: 0.9814214733203716\n",
      "Precision of RF: 0.9808432089597965\n",
      "Recall of RF: 0.9814214733203716\n",
      "F1-score of RF: 0.9793909056658823\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     18203\n",
      "           1       0.99      0.99      0.99       381\n",
      "           2       0.97      1.00      0.99        70\n",
      "           3       1.00      1.00      1.00        17\n",
      "           4       1.00      1.00      1.00       926\n",
      "           5       0.99      1.00      1.00       148\n",
      "           6       1.00      1.00      1.00       778\n",
      "           7       0.96      0.96      0.96        56\n",
      "           8       1.00      1.00      1.00       624\n",
      "           9       0.56      0.98      0.71       189\n",
      "          10       1.00      1.00      1.00      1017\n",
      "          11       0.97      0.45      0.62       261\n",
      "          12       0.31      0.16      0.22       219\n",
      "          13       0.75      1.00      0.86         3\n",
      "          14       1.00      1.00      1.00       253\n",
      "\n",
      "    accuracy                           0.98     23145\n",
      "   macro avg       0.90      0.90      0.89     23145\n",
      "weighted avg       0.98      0.98      0.98     23145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_hpo = RandomForestClassifier(n_estimators=188,              \n",
    "                                min_samples_leaf=2,\n",
    "                                max_depth=15, min_samples_split=4, max_features=16, criterion='entropy')\n",
    "rf_hpo.fit(X_train, y_train)\n",
    "rf_score = rf_hpo.score(X_test, y_test)\n",
    "y_predict = rf_hpo.predict(X_test)\n",
    "y_true = y_test\n",
    "print('Accuracy of RF: ' + str(rf_score))\n",
    "precision, recall, fscore, none = precision_recall_fscore_support(\n",
    "    y_true, y_predict, average='weighted')\n",
    "print('Precision of RF: '+(str(precision)))\n",
    "print('Recall of RF: '+(str(recall)))\n",
    "print('F1-score of RF: '+(str(fscore)))\n",
    "print(classification_report(y_true, y_predict))\n",
    "cm = confusion_matrix(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d35c3c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train = rf_hpo.predict(X_train)\n",
    "rf_test = rf_hpo.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b10a3f1",
   "metadata": {},
   "source": [
    "### Apply ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d104949c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ET: 0.9745085331605098\n",
      "Precision of ET: 0.9778417795563412\n",
      "Recall of ET: 0.9745085331605098\n",
      "F1-score of ET: 0.9748283959632693\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     18203\n",
      "           1       0.97      0.99      0.98       381\n",
      "           2       1.00      1.00      1.00        70\n",
      "           3       0.94      1.00      0.97        17\n",
      "           4       0.99      1.00      1.00       926\n",
      "           5       0.99      1.00      1.00       148\n",
      "           6       0.99      0.99      0.99       778\n",
      "           7       0.98      1.00      0.99        56\n",
      "           8       1.00      1.00      1.00       624\n",
      "           9       0.57      0.96      0.71       189\n",
      "          10       1.00      1.00      1.00      1017\n",
      "          11       0.95      0.47      0.63       261\n",
      "          12       0.14      0.16      0.15       219\n",
      "          13       1.00      1.00      1.00         3\n",
      "          14       1.00      1.00      1.00       253\n",
      "\n",
      "    accuracy                           0.97     23145\n",
      "   macro avg       0.90      0.90      0.89     23145\n",
      "weighted avg       0.98      0.97      0.97     23145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "et = ExtraTreesClassifier(random_state=0)\n",
    "et.fit(X_train, y_train)\n",
    "et_score = et.score(X_test, y_test)\n",
    "y_predict = et.predict(X_test)\n",
    "y_true = y_test\n",
    "print('Accuracy of ET: ' + str(et_score))\n",
    "precision, recall, fscore, none = precision_recall_fscore_support(\n",
    "    y_true, y_predict, average='weighted')\n",
    "print('Precision of ET: '+(str(precision)))\n",
    "print('Recall of ET: '+(str(recall)))\n",
    "print('F1-score of ET: '+(str(fscore)))\n",
    "print(classification_report(y_true, y_predict))\n",
    "cm = confusion_matrix(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ef4e31",
   "metadata": {},
   "source": [
    "#### Hyperparameter optimization (HPO) of extra trees using Bayesian optimization with tree-based Parzen estimator (BO-TPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0ba297ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [06:30<00:00, 17.77s/trial, best loss: -0.9812918556923742]\n",
      "Extra trees: Hyperopt estimated optimum {'criterion': 1, 'max_depth': 25.0, 'max_features': 19.0, 'min_samples_leaf': 2.0, 'min_samples_split': 4.0, 'n_estimators': 67.0}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter optimization of extra trees\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "\n",
    "# Define the objective function\n",
    "def objective(params):\n",
    "    params = {\n",
    "        'n_estimators': int(params['n_estimators']),\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'max_features': int(params['max_features']),\n",
    "        \"min_samples_split\": int(params['min_samples_split']),\n",
    "        \"min_samples_leaf\": int(params['min_samples_leaf']),\n",
    "        \"criterion\": str(params['criterion'])\n",
    "    }\n",
    "    clf = ExtraTreesClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "\n",
    "    return {'loss': -score, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "# Define the hyperparameter configuration space\n",
    "space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 10, 300, 1),\n",
    "    'max_depth': hp.quniform('max_depth', 5, 50, 1),\n",
    "    \"max_features\": hp.quniform('max_features', 1, 21, 1),\n",
    "    \"min_samples_split\": hp.quniform('min_samples_split', 2, 11, 1),\n",
    "    \"min_samples_leaf\": hp.quniform('min_samples_leaf', 1, 11, 1),\n",
    "    \"criterion\": hp.choice('criterion', ['gini', 'entropy'])\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=22)\n",
    "print(\"Extra trees: Hyperopt estimated optimum {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6cbd36dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ET: 0.9811190321883776\n",
      "Precision of ET: 0.9811492317447232\n",
      "Recall of ET: 0.9811190321883776\n",
      "F1-score of ET: 0.9795598426622655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     18203\n",
      "           1       0.98      0.99      0.99       381\n",
      "           2       1.00      1.00      1.00        70\n",
      "           3       0.94      1.00      0.97        17\n",
      "           4       1.00      1.00      1.00       926\n",
      "           5       0.99      1.00      1.00       148\n",
      "           6       1.00      1.00      1.00       778\n",
      "           7       0.93      1.00      0.97        56\n",
      "           8       1.00      1.00      1.00       624\n",
      "           9       0.56      0.97      0.71       189\n",
      "          10       1.00      1.00      1.00      1017\n",
      "          11       0.96      0.46      0.62       261\n",
      "          12       0.33      0.21      0.25       219\n",
      "          13       1.00      1.00      1.00         3\n",
      "          14       1.00      1.00      1.00       253\n",
      "\n",
      "    accuracy                           0.98     23145\n",
      "   macro avg       0.91      0.91      0.90     23145\n",
      "weighted avg       0.98      0.98      0.98     23145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "et_hpo = ExtraTreesClassifier(n_estimators=180, \n",
    "                              min_samples_leaf=2,\n",
    "                              max_depth=25, min_samples_split=4, max_features=19, criterion='entropy')\n",
    "et_hpo.fit(X_train, y_train)\n",
    "et_score = et_hpo.score(X_test, y_test)\n",
    "y_predict = et_hpo.predict(X_test)\n",
    "y_true = y_test\n",
    "print('Accuracy of ET: ' + str(et_score))\n",
    "precision, recall, fscore, none = precision_recall_fscore_support(\n",
    "    y_true, y_predict, average='weighted')\n",
    "print('Precision of ET: '+(str(precision)))\n",
    "print('Recall of ET: '+(str(recall)))\n",
    "print('F1-score of ET: '+(str(fscore)))\n",
    "print(classification_report(y_true, y_predict))\n",
    "cm = confusion_matrix(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2f630515",
   "metadata": {},
   "outputs": [],
   "source": [
    "et_train = et_hpo.predict(X_train)\n",
    "et_test = et_hpo.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecb7be3",
   "metadata": {},
   "source": [
    "### Apply XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "db26a71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:37:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy of XGBoost: 0.9800820911643984\n",
      "Precision of XGBoost: 0.9796395703908144\n",
      "Recall of XGBoost: 0.9800820911643984\n",
      "F1-score of XGBoost: 0.9781251996390391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     18203\n",
      "           1       0.96      0.99      0.97       381\n",
      "           2       0.99      1.00      0.99        70\n",
      "           3       0.94      1.00      0.97        17\n",
      "           4       1.00      1.00      1.00       926\n",
      "           5       0.99      1.00      1.00       148\n",
      "           6       1.00      1.00      1.00       778\n",
      "           7       0.90      0.96      0.93        56\n",
      "           8       0.99      0.99      0.99       624\n",
      "           9       0.56      0.98      0.72       189\n",
      "          10       1.00      0.99      0.99      1017\n",
      "          11       0.97      0.46      0.62       261\n",
      "          12       0.34      0.18      0.23       219\n",
      "          13       1.00      1.00      1.00         3\n",
      "          14       1.00      1.00      1.00       253\n",
      "\n",
      "    accuracy                           0.98     23145\n",
      "   macro avg       0.91      0.90      0.89     23145\n",
      "weighted avg       0.98      0.98      0.98     23145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg = xgb.XGBClassifier(n_estimators=10)\n",
    "xg.fit(X_train, y_train)\n",
    "xg_score = xg.score(X_test, y_test)\n",
    "y_predict = xg.predict(X_test)\n",
    "y_true = y_test\n",
    "print('Accuracy of XGBoost: ' + str(xg_score))\n",
    "precision, recall, fscore, none = precision_recall_fscore_support(\n",
    "    y_true, y_predict, average='weighted')\n",
    "print('Precision of XGBoost: '+(str(precision)))\n",
    "print('Recall of XGBoost: '+(str(recall)))\n",
    "print('F1-score of XGBoost: '+(str(fscore)))\n",
    "print(classification_report(y_true, y_predict))\n",
    "cm = confusion_matrix(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccd1be0",
   "metadata": {},
   "source": [
    "#### Hyperparameter optimization (HPO) of XGBoost using Bayesian optimization with tree-based Parzen estimator (BO-TPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "384e664d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [06:21<00:00, 17.35s/trial, best loss: -0.9800820911643984]\n",
      "XGBoost: Hyperopt estimated optimum {'learning_rate': 0.1995531459500868, 'max_depth': 13.0, 'n_estimators': 100.0}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "def objective(params):\n",
    "    params = {\n",
    "        'n_estimators': int(params['n_estimators']),\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'learning_rate':  abs(float(params['learning_rate']))\n",
    "    }\n",
    "    clf = xgb.XGBClassifier(**params,\n",
    "                            eval_metric='mlogloss')\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return {'loss': -score, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 10, 100, 5),\n",
    "    'max_depth': hp.quniform('max_depth', 4, 100, 1),\n",
    "    'learning_rate': hp.normal('learning_rate', 0.0001, 0.99),\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=22)\n",
    "print(\"XGBoost: Hyperopt estimated optimum {}\".format(best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "56c702de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:53:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy of XGBoost: 0.9814214733203716\n",
      "Precision of XGBoost: 0.9808749379360137\n",
      "Recall of XGBoost: 0.9814214733203716\n",
      "F1-score of XGBoost: 0.979654146434537\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     18203\n",
      "           1       0.98      0.99      0.99       381\n",
      "           2       0.97      1.00      0.99        70\n",
      "           3       1.00      1.00      1.00        17\n",
      "           4       1.00      1.00      1.00       926\n",
      "           5       0.99      1.00      1.00       148\n",
      "           6       1.00      1.00      1.00       778\n",
      "           7       0.98      0.96      0.97        56\n",
      "           8       1.00      1.00      1.00       624\n",
      "           9       0.56      0.96      0.71       189\n",
      "          10       1.00      1.00      1.00      1017\n",
      "          11       0.94      0.47      0.62       261\n",
      "          12       0.33      0.19      0.24       219\n",
      "          13       1.00      1.00      1.00         3\n",
      "          14       1.00      1.00      1.00       253\n",
      "\n",
      "    accuracy                           0.98     23145\n",
      "   macro avg       0.92      0.90      0.90     23145\n",
      "weighted avg       0.98      0.98      0.98     23145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg = xgb.XGBClassifier(learning_rate=0.3019765375509075,\n",
    "                       n_estimators=45, max_depth=5)\n",
    "xg.fit(X_train, y_train)\n",
    "xg_score = xg.score(X_test, y_test)\n",
    "y_predict = xg.predict(X_test)\n",
    "y_true = y_test\n",
    "print('Accuracy of XGBoost: ' + str(xg_score))\n",
    "precision, recall, fscore, none = precision_recall_fscore_support(\n",
    "    y_true, y_predict, average='weighted')\n",
    "print('Precision of XGBoost: '+(str(precision)))\n",
    "print('Recall of XGBoost: '+(str(recall)))\n",
    "print('F1-score of XGBoost: '+(str(fscore)))\n",
    "print(classification_report(y_true, y_predict))\n",
    "cm = confusion_matrix(y_true, y_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3e1fabf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_train = xg.predict(X_train)\n",
    "xg_test = xg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d841893",
   "metadata": {},
   "source": [
    "### Apply stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dda98a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DecisionTree</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>ExtraTrees</th>\n",
       "      <th>XgBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DecisionTree  RandomForest  ExtraTrees  XgBoost\n",
       "0             0             0           0        0\n",
       "1             1             1           1        1\n",
       "2             0             0           0        0\n",
       "3             4             4           4        4\n",
       "4            10            10          10       10"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_predictions_train = pd.DataFrame({\n",
    "    'DecisionTree': dt_train.ravel(),\n",
    "    'RandomForest': rf_train.ravel(),\n",
    "    'ExtraTrees': et_train.ravel(),\n",
    "    'XgBoost': xg_train.ravel(),\n",
    "})\n",
    "base_predictions_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5f74e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train = dt_train.reshape(-1, 1)\n",
    "et_train = et_train.reshape(-1, 1)\n",
    "rf_train = rf_train.reshape(-1, 1)\n",
    "xg_train = xg_train.reshape(-1, 1)\n",
    "dt_test = dt_test.reshape(-1, 1)\n",
    "et_test = et_test.reshape(-1, 1)\n",
    "rf_test = rf_test.reshape(-1, 1)\n",
    "xg_test = xg_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "19f661f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83287, 1)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2fc2fa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate((dt_train, et_train, rf_train, xg_train), axis=1)\n",
    "x_test = np.concatenate((dt_test, et_test, rf_test, xg_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c82eb716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:01:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy of Stacking: 0.9801252970403975\n",
      "Precision of Stacking: 0.9806980204558118\n",
      "Recall of Stacking: 0.9801252970403975\n",
      "F1-score of Stacking: 0.9790631596446348\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     18203\n",
      "           1       0.99      0.99      0.99       381\n",
      "           2       0.99      1.00      0.99        70\n",
      "           3       1.00      1.00      1.00        17\n",
      "           4       1.00      1.00      1.00       926\n",
      "           5       0.99      1.00      1.00       148\n",
      "           6       1.00      1.00      1.00       778\n",
      "           7       0.98      0.96      0.97        56\n",
      "           8       1.00      1.00      1.00       624\n",
      "           9       0.56      0.96      0.71       189\n",
      "          10       1.00      1.00      1.00      1017\n",
      "          11       0.94      0.47      0.62       261\n",
      "          12       0.28      0.21      0.24       219\n",
      "          13       1.00      1.00      1.00         3\n",
      "          14       1.00      1.00      1.00       253\n",
      "\n",
      "    accuracy                           0.98     23145\n",
      "   macro avg       0.91      0.91      0.90     23145\n",
      "weighted avg       0.98      0.98      0.98     23145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stk = xgb.XGBClassifier().fit(x_train, y_train)\n",
    "y_predict = stk.predict(x_test)\n",
    "y_true = y_test\n",
    "stk_score = accuracy_score(y_true, y_predict)\n",
    "print('Accuracy of Stacking: ' + str(stk_score))\n",
    "precision, recall, fscore, none = precision_recall_fscore_support(\n",
    "    y_true, y_predict, average='weighted')\n",
    "print('Precision of Stacking: '+(str(precision)))\n",
    "print('Recall of Stacking: '+(str(recall)))\n",
    "print('F1-score of Stacking: '+(str(fscore)))\n",
    "print(classification_report(y_true, y_predict))\n",
    "cm = confusion_matrix(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69adae39",
   "metadata": {},
   "source": [
    "#### Hyperparameter optimization (HPO) of the stacking ensemble model (XGBoost) using Bayesian optimization with tree-based Parzen estimator (BO-TPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cec779fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [01:00<00:00,  2.75s/trial, best loss: -0.9801252970403975]\n",
      "XGBoost: Hyperopt estimated optimum {'learning_rate': 0.5706529343600486, 'max_depth': 98.0, 'n_estimators': 35.0}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "\n",
    "def objective(params):\n",
    "    params = {\n",
    "        'n_estimators': int(params['n_estimators']),\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'learning_rate':  abs(float(params['learning_rate'])),\n",
    "\n",
    "    }\n",
    "    clf = xgb.XGBClassifier(**params,  eval_metric='logloss')\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return {'loss': -score, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 10, 100, 5),\n",
    "    'max_depth': hp.quniform('max_depth', 4, 100, 1),\n",
    "    'learning_rate': hp.normal('learning_rate', 0.01, 0.9),\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=22)\n",
    "print(\"XGBoost: Hyperopt estimated optimum {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5497af02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:11:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy of XGBoost: 0.9801252970403975\n",
      "Precision of XGBoost: 0.9807250312192217\n",
      "Recall of XGBoost: 0.9801252970403975\n",
      "F1-score of XGBoost: 0.979078627833479\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     18203\n",
      "           1       0.99      0.99      0.99       381\n",
      "           2       0.99      1.00      0.99        70\n",
      "           3       1.00      1.00      1.00        17\n",
      "           4       1.00      1.00      1.00       926\n",
      "           5       0.99      1.00      1.00       148\n",
      "           6       1.00      1.00      1.00       778\n",
      "           7       0.98      0.96      0.97        56\n",
      "           8       1.00      1.00      1.00       624\n",
      "           9       0.56      0.96      0.71       189\n",
      "          10       1.00      1.00      1.00      1017\n",
      "          11       0.94      0.47      0.62       261\n",
      "          12       0.28      0.21      0.24       219\n",
      "          13       1.00      1.00      1.00         3\n",
      "          14       1.00      1.00      1.00       253\n",
      "\n",
      "    accuracy                           0.98     23145\n",
      "   macro avg       0.91      0.91      0.90     23145\n",
      "weighted avg       0.98      0.98      0.98     23145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg = xgb.XGBClassifier(learning_rate=0.1947844980138047,\n",
    "                       n_estimators=55, max_depth=55)\n",
    "xg.fit(x_train, y_train)\n",
    "xg_score = xg.score(x_test, y_test)\n",
    "y_predict = xg.predict(x_test)\n",
    "y_true = y_test\n",
    "print('Accuracy of XGBoost: ' + str(xg_score))\n",
    "precision, recall, fscore, none = precision_recall_fscore_support(\n",
    "    y_true, y_predict, average='weighted')\n",
    "print('Precision of XGBoost: '+(str(precision)))\n",
    "print('Recall of XGBoost: '+(str(recall)))\n",
    "print('F1-score of XGBoost: '+(str(fscore)))\n",
    "print(classification_report(y_true, y_predict))\n",
    "cm = confusion_matrix(y_true, y_predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc07dfe",
   "metadata": {},
   "source": [
    "### Anomaly-based IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "2644d773",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    './CICIDS_2018/CICIDS2018_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9798ff",
   "metadata": {},
   "source": [
    "#### Feature engineering (IG and FCBF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072869dc",
   "metadata": {},
   "source": [
    "#### Feature selection by information gain (IG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "ccd0f086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "importances = mutual_info_classif(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "aa4ae879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the sum of importance scores\n",
    "f_list = sorted(\n",
    "    zip(map(lambda x: round(x, 4), importances), features), reverse=True)\n",
    "Sum = 0\n",
    "fs = []\n",
    "for i in range(0, len(f_list)):\n",
    "    Sum = Sum + f_list[i][0]\n",
    "    fs.append(f_list[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "268e1032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the important features from top to bottom until the accumulated importance reaches 90%\n",
    "f_list2 = sorted(\n",
    "    zip(map(lambda x: round(x, 4), importances/Sum), features), reverse=True)\n",
    "Sum2 = 0\n",
    "fs = []\n",
    "for i in range(0, len(f_list2)):\n",
    "    Sum2 = Sum2 + f_list2[i][0]\n",
    "    fs.append(f_list2[i][1])\n",
    "    if Sum2 >= 0.9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "8c7674c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fs = df_frac[fs].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "edfe75a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4009, 45)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cd1bd5",
   "metadata": {},
   "source": [
    "#### Feature selection by Fast Correlation Based Filter (FCBF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "f0e56558",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FCBF_module import FCBF, FCBFK, FCBFiP, get_i\n",
    "fcbf = FCBFK(k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "926d1b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fss = fcbf.fit_transform(X_fs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "9aca8ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4009, 20)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fss.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171f040e",
   "metadata": {},
   "source": [
    "####  kernel principal component analysis (KPCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "1a46b06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "kpca = KernelPCA(n_components=10, kernel='rbf')\n",
    "kpca.fit(X_fss, y)\n",
    "X_kpca = kpca.transform(X_fss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afb913b",
   "metadata": {},
   "source": [
    "### Train-test split after feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "636838b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_kpca, y, train_size=0.7, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0109bb2a",
   "metadata": {},
   "source": [
    "### Solve class-imbalance by SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "15aefa20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2263\n",
       "1     543\n",
       "dtype: int64"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "4d0aabaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(n_jobs=-1)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "6b658ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    975\n",
       "1    228\n",
       "dtype: int64"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_test).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9556a18",
   "metadata": {},
   "source": [
    "### Apply the cluster labeling (CL) k-means method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "aaa4a73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN, MeanShift\n",
    "from sklearn.cluster import SpectralClustering, AgglomerativeClustering, AffinityPropagation, Birch, MiniBatchKMeans, MeanShift\n",
    "from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "ec5e890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CL_kmeans(X_train, X_test, y_train, y_test, n):\n",
    "    km_cluster = KMeans(n_clusters=n)\n",
    "    result = km_cluster.fit_predict(X_train)\n",
    "    result2 = km_cluster.predict(X_test)\n",
    "\n",
    "    count = 0\n",
    "    a = np.zeros(n)\n",
    "    b = np.zeros(n)\n",
    "    for v in range(0, n):\n",
    "        for i in range(0, len(y_train)):\n",
    "            if result[i] == v:\n",
    "                if y_train[i] == 1:\n",
    "                    a[v] = a[v]+1\n",
    "                else:\n",
    "                    b[v] = b[v]+1\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    for v in range(0, n):\n",
    "        if a[v] <= b[v]:\n",
    "            list1.append(v)\n",
    "        else:\n",
    "            list2.append(v)\n",
    "    for v in range(0, len(y_test)):\n",
    "        if result2[v] in list1:\n",
    "            result2[v] = 0\n",
    "        elif result2[v] in list2:\n",
    "            result2[v] = 1\n",
    "        else:\n",
    "            print(\"-1\")\n",
    "    print(classification_report(y_test, result2))\n",
    "    cm = confusion_matrix(y_test, result2)\n",
    "    acc = metrics.accuracy_score(y_test, result2)\n",
    "    print(str(acc))\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "49ed7050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       975\n",
      "           1       0.90      0.93      0.91       228\n",
      "\n",
      "    accuracy                           0.97      1203\n",
      "   macro avg       0.94      0.95      0.95      1203\n",
      "weighted avg       0.97      0.97      0.97      1203\n",
      "\n",
      "0.9667497921862012\n",
      "[[952  23]\n",
      " [ 17 211]]\n"
     ]
    }
   ],
   "source": [
    "CL_kmeans(X_train, X_test, y_train, y_test, 135)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396d670a",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization of CL-k-means\n",
    "Tune \"k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "10ad9bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-optimize in c:\\users\\flore\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.9.0)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\flore\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-optimize) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\flore\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-optimize) (1.19.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\flore\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\flore\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-optimize) (1.0.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\flore\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-optimize) (1.0.1)\n",
      "Requirement already satisfied: pyaml>=16.9 in c:\\users\\flore\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-optimize) (21.10.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\flore\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyaml>=16.9->scikit-optimize) (5.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\flore\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn>=0.20.0->scikit-optimize) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "1a985c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 0.9027431421446384\n",
      "43 0.9010806317539485\n",
      "43 0.942643391521197\n",
      "43 0.9459684123025769\n",
      "32 0.9301745635910225\n",
      "20 0.8686616791354946\n",
      "16 0.8603491271820449\n",
      "5 0.8595178719866999\n",
      "15 0.857024106400665\n",
      "25 0.8703241895261845\n",
      "50 0.9526184538653366\n",
      "50 0.9376558603491272\n",
      "50 0.9068994181213632\n",
      "50 0.9501246882793017\n",
      "50 0.8927680798004988\n",
      "40 0.943474646716542\n",
      "42 0.9177057356608479\n",
      "50 0.9625935162094763\n",
      "50 0.9293433083956775\n",
      "50 0.913549459684123\n",
      "14.466262340545654\n",
      "Best score=0.9626\n",
      "Best parameters: n_clusters=50\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter optimization by BO-GP\n",
    "from skopt import gp_minimize\n",
    "import time\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from sklearn import metrics\n",
    "\n",
    "space = [Integer(2, 50, name='n_clusters')]\n",
    "\n",
    "\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    km_cluster = MiniBatchKMeans(batch_size=100, **params)\n",
    "    n = params['n_clusters']\n",
    "\n",
    "    result = km_cluster.fit_predict(X_train)\n",
    "    result2 = km_cluster.predict(X_test)\n",
    "\n",
    "    count = 0\n",
    "    a = np.zeros(n)\n",
    "    b = np.zeros(n)\n",
    "    for v in range(0, n):\n",
    "        for i in range(0, len(y_train)):\n",
    "            if result[i] == v:\n",
    "                if y_train[i] == 1:\n",
    "                    a[v] = a[v]+1\n",
    "                else:\n",
    "                    b[v] = b[v]+1\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    for v in range(0, n):\n",
    "        if a[v] <= b[v]:\n",
    "            list1.append(v)\n",
    "        else:\n",
    "            list2.append(v)\n",
    "    for v in range(0, len(y_test)):\n",
    "        if result2[v] in list1:\n",
    "            result2[v] = 0\n",
    "        elif result2[v] in list2:\n",
    "            result2[v] = 1\n",
    "        else:\n",
    "            print(\"-1\")\n",
    "    cm = metrics.accuracy_score(y_test, result2)\n",
    "    print(str(n)+\" \"+str(cm))\n",
    "    return (1-cm)\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "res_gp = gp_minimize(objective, space, n_calls=20, random_state=0)\n",
    "t2 = time.time()\n",
    "print(t2-t1)\n",
    "print(\"Best score=%.4f\" % (1-res_gp.fun))\n",
    "print(\"\"\"Best parameters: n_clusters=%d\"\"\" % (res_gp.x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "1a53cdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 0.9467996674979219                                 \n",
      "26 0.8877805486284289                                                            \n",
      "16 0.8420615128844555                                                            \n",
      "41 0.9310058187863675                                                            \n",
      "34 0.9093931837073982                                                            \n",
      "25 0.8769742310889443                                                            \n",
      "4 0.6974231088944306                                                             \n",
      "4 0.6774729842061513                                                             \n",
      "13 0.8320864505403158                                                            \n",
      "46 0.943474646716542                                                             \n",
      "45 0.9260182876142976                                                             \n",
      "32 0.9384871155444722                                                             \n",
      "49 0.9376558603491272                                                             \n",
      "28 0.885286783042394                                                              \n",
      "38 0.941812136325852                                                              \n",
      "19 0.8902743142144638                                                             \n",
      "33 0.9152119700748129                                                             \n",
      "44 0.9476309226932669                                                             \n",
      "6 0.7090606816292602                                                               \n",
      "49 0.9326683291770573                                                              \n",
      "100%|██████████| 20/20 [00:12<00:00,  1.58trial/s, best loss: 0.052369077306733125]\n",
      "Random Forest: Hyperopt estimated optimum {'n_clusters': 44.0}\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter optimization by BO-TPE\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "def objective(params):\n",
    "    params = {\n",
    "        'n_clusters': int(params['n_clusters']),\n",
    "    }\n",
    "    km_cluster = MiniBatchKMeans(batch_size=100, **params)\n",
    "    n = params['n_clusters']\n",
    "\n",
    "    result = km_cluster.fit_predict(X_train)\n",
    "    result2 = km_cluster.predict(X_test)\n",
    "\n",
    "    count = 0\n",
    "    a = np.zeros(n)\n",
    "    b = np.zeros(n)\n",
    "    for v in range(0, n):\n",
    "        for i in range(0, len(y_train)):\n",
    "            if result[i] == v:\n",
    "                if y_train[i] == 1:\n",
    "                    a[v] = a[v]+1\n",
    "                else:\n",
    "                    b[v] = b[v]+1\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    for v in range(0, n):\n",
    "        if a[v] <= b[v]:\n",
    "            list1.append(v)\n",
    "        else:\n",
    "            list2.append(v)\n",
    "    for v in range(0, len(y_test)):\n",
    "        if result2[v] in list1:\n",
    "            result2[v] = 0\n",
    "        elif result2[v] in list2:\n",
    "            result2[v] = 1\n",
    "        else:\n",
    "            print(\"-1\")\n",
    "    score = metrics.accuracy_score(y_test, result2)\n",
    "    print(str(params['n_clusters'])+\" \"+str(score))\n",
    "    return {'loss': 1-score, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "space = {\n",
    "    'n_clusters': hp.quniform('n_clusters', 2, 50, 1),\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20)\n",
    "print(\"Random Forest: Hyperopt estimated optimum {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "01485315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       975\n",
      "           1       0.90      0.90      0.90       228\n",
      "\n",
      "    accuracy                           0.96      1203\n",
      "   macro avg       0.94      0.94      0.94      1203\n",
      "weighted avg       0.96      0.96      0.96      1203\n",
      "\n",
      "0.9617622610141313\n",
      "[[952  23]\n",
      " [ 23 205]]\n"
     ]
    }
   ],
   "source": [
    "CL_kmeans(X_train, X_test, y_train, y_test, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d467e4e8",
   "metadata": {},
   "source": [
    "### Apply the CL-k-means model with biased classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "8eb50f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs to work on the entire dataset to generate sufficient training samples for biased classifiers\n",
    "def Anomaly_IDS(X_train, X_test, y_train, y_test, n, b=100):\n",
    "    # CL-kmeans\n",
    "    km_cluster = MiniBatchKMeans(n_clusters=n, batch_size=b)\n",
    "    result = km_cluster.fit_predict(X_train)\n",
    "    result2 = km_cluster.predict(X_test)\n",
    "\n",
    "    count = 0\n",
    "    a = np.zeros(n)\n",
    "    b = np.zeros(n)\n",
    "    for v in range(0, n):\n",
    "        for i in range(0, len(y_train)):\n",
    "            if result[i] == v:\n",
    "                if y_train[i] == 1:\n",
    "                    a[v] = a[v]+1\n",
    "                else:\n",
    "                    b[v] = b[v]+1\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    for v in range(0, n):\n",
    "        if a[v] <= b[v]:\n",
    "            list1.append(v)\n",
    "        else:\n",
    "            list2.append(v)\n",
    "    for v in range(0, len(y_test)):\n",
    "        if result2[v] in list1:\n",
    "            result2[v] = 0\n",
    "        elif result2[v] in list2:\n",
    "            result2[v] = 1\n",
    "        else:\n",
    "            print(\"-1\")\n",
    "    print(classification_report(y_test, result2))\n",
    "    cm = confusion_matrix(y_test, result2)\n",
    "    acc = metrics.accuracy_score(y_test, result2)\n",
    "    print(str(acc))\n",
    "    print(cm)\n",
    "\n",
    "    #Biased classifier construction\n",
    "    count = 0\n",
    "    print(len(y))\n",
    "    a = np.zeros(n)\n",
    "    b = np.zeros(n)\n",
    "    FNL = []\n",
    "    FPL = []\n",
    "    for v in range(0, n):\n",
    "        al = []\n",
    "        bl = []\n",
    "        for i in range(0, len(y)):\n",
    "            if result[i] == v:\n",
    "                if y[i] == 1:  # label 1\n",
    "                    a[v] = a[v]+1\n",
    "                    al.append(i)\n",
    "                else:  # label 0\n",
    "                    b[v] = b[v]+1\n",
    "                    bl.append(i)\n",
    "        if a[v] <= b[v]:\n",
    "            FNL.extend(al)\n",
    "        else:\n",
    "            FPL.extend(bl)\n",
    "\n",
    "    dffp = df.iloc[FPL, :]\n",
    "    dffn = df.iloc[FNL, :]\n",
    "    dfva0 = df[df['Label'] == 0]\n",
    "    dfva1 = df[df['Label'] == 1]\n",
    "\n",
    "    dffpp = dfva1.sample(n=None, frac=len(\n",
    "        FPL)/dfva1.shape[0], replace=False, weights=None, random_state=None, axis=0)\n",
    "    dffnp = dfva0.sample(n=None, frac=len(\n",
    "        FNL)/dfva0.shape[0], replace=False, weights=None, random_state=None, axis=0)\n",
    "\n",
    "    dffp_f = pd.concat([dffp, dffpp])\n",
    "    dffn_f = pd.concat([dffn, dffnp])\n",
    "\n",
    "    Xp = dffp_f.drop(['Label'], axis=1)\n",
    "    yp = dffp_f.iloc[:, -1].values.reshape(-1, 1)\n",
    "    yp = np.ravel(yp)\n",
    "\n",
    "    Xn = dffn_f.drop(['Label'], axis=1)\n",
    "    yn = dffn_f.iloc[:, -1].values.reshape(-1, 1)\n",
    "    yn = np.ravel(yn)\n",
    "\n",
    "    rfp = RandomForestClassifier(random_state=0)\n",
    "    rfp.fit(Xp, yp)\n",
    "    rfn = RandomForestClassifier(random_state=0)\n",
    "    rfn.fit(Xn, yn)\n",
    "\n",
    "    dffnn_f = pd.concat([dffn, dffnp])\n",
    "\n",
    "    Xnn = dffn_f.drop(['Label'], axis=1)\n",
    "    ynn = dffn_f.iloc[:, -1].values.reshape(-1, 1)\n",
    "    ynn = np.ravel(ynn)\n",
    "\n",
    "    rfnn = RandomForestClassifier(random_state=0)\n",
    "    rfnn.fit(Xnn, ynn)\n",
    "\n",
    "    X2p = df2.drop(['Label'], axis=1)\n",
    "    y2p = df2.iloc[:, -1].values.reshape(-1, 1)\n",
    "    y2p = np.ravel(y2p)\n",
    "\n",
    "    result2 = km_cluster.predict(X2p)\n",
    "\n",
    "    count = 0\n",
    "    a = np.zeros(n)\n",
    "    b = np.zeros(n)\n",
    "    for v in range(0, n):\n",
    "        for i in range(0, len(y)):\n",
    "            if result[i] == v:\n",
    "                if y[i] == 1:\n",
    "                    a[v] = a[v]+1\n",
    "                else:\n",
    "                    b[v] = b[v]+1\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    l1 = []\n",
    "    l0 = []\n",
    "    for v in range(0, n):\n",
    "        if a[v] <= b[v]:\n",
    "            list1.append(v)\n",
    "        else:\n",
    "            list2.append(v)\n",
    "    for v in range(0, len(y2p)):\n",
    "        if result2[v] in list1:\n",
    "            result2[v] = 0\n",
    "            l0.append(v)\n",
    "        elif result2[v] in list2:\n",
    "            result2[v] = 1\n",
    "            l1.append(v)\n",
    "        else:\n",
    "            print(\"-1\")\n",
    "    print(classification_report(y2p, result2))\n",
    "    cm = confusion_matrix(y2p, result2)\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "f46b70c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       975\n",
      "           1       0.85      0.89      0.87       228\n",
      "\n",
      "    accuracy                           0.95      1203\n",
      "   macro avg       0.91      0.93      0.92      1203\n",
      "weighted avg       0.95      0.95      0.95      1203\n",
      "\n",
      "0.9492934330839568\n",
      "[[938  37]\n",
      " [ 24 204]]\n",
      "4009\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 76)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\flore\\Downloads\\Intrusion-Detection-System-Using-Machine-Learning\\IDS_KMeans.ipynb Cell 130'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/flore/Downloads/Intrusion-Detection-System-Using-Machine-Learning/IDS_KMeans.ipynb#ch0000140?line=0'>1</a>\u001b[0m Anomaly_IDS(X_train, X_test, y_train, y_test, \u001b[39m42\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\flore\\Downloads\\Intrusion-Detection-System-Using-Machine-Learning\\IDS_KMeans.ipynb Cell 129'\u001b[0m in \u001b[0;36mAnomaly_IDS\u001b[1;34m(X_train, X_test, y_train, y_test, n, b)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/flore/Downloads/Intrusion-Detection-System-Using-Machine-Learning/IDS_KMeans.ipynb#ch0000139?line=79'>80</a>\u001b[0m yn \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mravel(yn)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/flore/Downloads/Intrusion-Detection-System-Using-Machine-Learning/IDS_KMeans.ipynb#ch0000139?line=81'>82</a>\u001b[0m rfp \u001b[39m=\u001b[39m RandomForestClassifier(random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/flore/Downloads/Intrusion-Detection-System-Using-Machine-Learning/IDS_KMeans.ipynb#ch0000139?line=82'>83</a>\u001b[0m rfp\u001b[39m.\u001b[39;49mfit(Xp, yp)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/flore/Downloads/Intrusion-Detection-System-Using-Machine-Learning/IDS_KMeans.ipynb#ch0000139?line=83'>84</a>\u001b[0m rfn \u001b[39m=\u001b[39m RandomForestClassifier(random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/flore/Downloads/Intrusion-Detection-System-Using-Machine-Learning/IDS_KMeans.ipynb#ch0000139?line=84'>85</a>\u001b[0m rfn\u001b[39m.\u001b[39mfit(Xn, yn)\n",
      "File \u001b[1;32mc:\\Users\\flore\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:327\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/ensemble/_forest.py?line=324'>325</a>\u001b[0m \u001b[39mif\u001b[39;00m issparse(y):\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/ensemble/_forest.py?line=325'>326</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/ensemble/_forest.py?line=326'>327</a>\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/ensemble/_forest.py?line=327'>328</a>\u001b[0m     X, y, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mDTYPE\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/ensemble/_forest.py?line=328'>329</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/ensemble/_forest.py?line=329'>330</a>\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/ensemble/_forest.py?line=330'>331</a>\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32mc:\\Users\\flore\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/base.py?line=578'>579</a>\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/base.py?line=579'>580</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/base.py?line=580'>581</a>\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/base.py?line=581'>582</a>\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/base.py?line=583'>584</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\flore\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:964\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/validation.py?line=960'>961</a>\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/validation.py?line=961'>962</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39my cannot be None\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/validation.py?line=963'>964</a>\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/validation.py?line=964'>965</a>\u001b[0m     X,\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/validation.py?line=965'>966</a>\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/validation.py?line=966'>967</a>\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/validation.py?line=967'>968</a>\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/validation.py?line=968'>969</a>\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/validation.py?line=969'>970</a>\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/validation.py?line=970'>971</a>\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/validation.py?line=971'>972</a>\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/validation.py?line=972'>973</a>\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/validation.py?line=973'>974</a>\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/validation.py?line=974'>975</a>\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/validation.py?line=975'>976</a>\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/validation.py?line=976'>977</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/validation.py?line=978'>979</a>\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric)\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/validation.py?line=980'>981</a>\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\flore\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:805\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/validation.py?line=802'>803</a>\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/validation.py?line=803'>804</a>\u001b[0m     \u001b[39mif\u001b[39;00m n_samples \u001b[39m<\u001b[39m ensure_min_samples:\n\u001b[1;32m--> <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/validation.py?line=804'>805</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/validation.py?line=805'>806</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m sample(s) (shape=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) while a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/validation.py?line=806'>807</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m minimum of \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m is required\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/validation.py?line=807'>808</a>\u001b[0m             \u001b[39m%\u001b[39m (n_samples, array\u001b[39m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/validation.py?line=808'>809</a>\u001b[0m         )\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/validation.py?line=810'>811</a>\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_features \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/flore/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/validation.py?line=811'>812</a>\u001b[0m     n_features \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 76)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "Anomaly_IDS(X_train, X_test, y_train, y_test, 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce31020",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e530f7",
   "metadata": {},
   "source": [
    "#### Import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "9e992de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import itertools\n",
    "import pickle\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from tensorflow.python.ops import array_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "5478bca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(prediction_tensor, target_tensor, weights=None, alpha=0.25, gamma=2):\n",
    "    sigmoid_p = tf.nn.sigmoid(prediction_tensor)\n",
    "    zeros = array_ops.zeros_like(sigmoid_p, dtype=sigmoid_p.dtype)\n",
    "    pos_p_sub = array_ops.where(target_tensor > zeros, target_tensor - sigmoid_p, zeros)\n",
    "    neg_p_sub = array_ops.where(target_tensor > zeros, zeros, sigmoid_p)\n",
    "    per_entry_cross_ent = - alpha * (pos_p_sub ** gamma) * tf.log(tf.clip_by_value(sigmoid_p, 1e-8, 1.0)) \\\n",
    "                          - (1 - alpha) * (neg_p_sub ** gamma) * tf.log(tf.clip_by_value(1.0 - sigmoid_p, 1e-8, 1.0))\n",
    "    return tf.reduce_sum(per_entry_cross_ent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "4534656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "ec6bdabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the confusion matrix.\n",
    "cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_confusion_matrix():\n",
    "    # Use the model to predict the values from the validation dataset.\n",
    "    test_pred_raw = model.predict(test_traffic)\n",
    "    test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "\n",
    "    # Calculate the confusion matrix.\n",
    "    cm = sklearn.metrics.confusion_matrix(test_classes, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeca0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_classification = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100758fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = training.to_numpy(dtype='float32')[:-237, :]\n",
    "train_traffic = training[:, :-2]\n",
    "train_labels = training[:, -1].astype(np.uint8)\n",
    "train_classes = training[:, -2].astype(np.uint8)\n",
    "testing = testing.to_numpy(dtype='float32')\n",
    "test_traffic = testing[:, :-2]\n",
    "test_labels = testing[:, -1].astype(np.uint8)\n",
    "test_classes = testing[:, -2].astype(np.uint8)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "517da064f6d1f3af3cee9b8300d52c6aac557afab54e540b991e49354cc462aa"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
